---
title: "Local GraphRAG | llama.cpp: ä½¿ç”¨åœ°ç«¯ LLM"
author: "ChiChieh Huang"
date: 2024-11-06T09:27:26.434+0000
last_modified_at: 2025-02-20T10:55:35.749+0000
categories: [""]
tags: ["llm","ai","tutorial","graphrag","ä¸­æ–‡"]
description: "é€™ç¯‡æ–‡ç« ä¾¿æ˜¯å¸Œæœ›å¸¶å¤§å®¶ä¸€èµ·æ“ä½œï¼Œå¦‚ä½•åœ¨ Microsoft GraphRAG ä¸­ä½¿ç”¨llama.cpp æ¶è¨­çš„åœ°ç«¯ LLM ä¼ºæœå™¨ï¼Œä¸»è¦æœƒåˆ†æˆå…©æ­¥é©Ÿï¼š A. å•Ÿå‹• llama.cpp ä¼ºæœå™¨ B. Microsoft GraphRAG"
image:
  path: /assets/895bb92b0c08/1*tInzlVhHANaOweOsiiYiow.png
render_with_liquid: false
---

### Local GraphRAG \| llama\.cpp: ä½¿ç”¨åœ°ç«¯ LLM


![](/assets/895bb92b0c08/1*tInzlVhHANaOweOsiiYiow.png)


åœ¨ç¾ä»Šçš„ä¼æ¥­æ‡‰ç”¨ä¸­ï¼ŒGraphRAG å·²æˆç‚ºè¨±å¤š LLM æ‡‰ç”¨ä¸­çš„é‡è¦åŠŸèƒ½ã€‚ç„¶è€Œï¼ŒMicrosoft çš„ GraphRAG éœ€è¦ä»˜è²»ï¼Œä¸”å¿…é ˆå°‡è³‡æ–™ä¸Šå‚³è‡³å•†æ¥­ LLM å¹³å°ï¼Œé€™å°æ–¼ä¸€äº›ä¼æ¥­è€Œè¨€å¯èƒ½ä¸¦ä¸ç†æƒ³ã€‚å› æ­¤ï¼Œå¦‚ä½•åˆ©ç”¨è‡ªæœ‰çš„ LLM æ¨¡å‹ä¾†å»ºç«‹ Microsoft GraphRAGï¼Œæˆç‚ºè¶Šä¾†è¶Šå¤šäººé—œæ³¨çš„è§£æ±ºæ–¹æ¡ˆã€‚

Microsoft GraphRAG ä¸»è¦æ˜¯è¨­è¨ˆçµ¦ä½¿ç”¨è€…é¸æ“‡ OpenAI æˆ– Azure OpenAI çš„ LLM ä¾†åŸ·è¡Œï¼Œè‹¥ä½ å°æ­¤æŠ€è¡“é‚„ä¸ç†Ÿæ‚‰ï¼Œå¯ä»¥å…ˆåƒè€ƒæˆ‘å…ˆå‰çš„ [æ•™å­¸æ–‡ç« ](../ac07991855e6/) äº†è§£åŸºç¤æ¦‚å¿µã€‚å¦‚ä»Šï¼Œæœ‰ä¸å°‘é–‹ç™¼è€…åœ¨ GitHub ä¸Šæä¾›äº†é–‹æºçš„ Local GraphRAG æ–¹æ³•ï¼Œè®“å¤§å®¶èƒ½å¤ é€éåœ°ç«¯çš„ LLM ä¾†å¯¦ç¾ç›¸ä¼¼çš„æ•ˆæœã€‚ä»¥ä¸‹æ˜¯å…©å€‹å€¼å¾—åƒè€ƒçš„ repoï¼š
- [**GraphRAG\-Local\-UI**](https://github.com/severian42/GraphRAG-Local-UI){:target="_blank"} ï¼šæä¾›äº†ä½¿ç”¨è€…å‹å¥½çš„åœ–å½¢ä»‹é¢ï¼ˆUIï¼‰ï¼Œæ–¹ä¾¿æ“ä½œã€‚
- [**graphrag\-local\-ollama**](https://github.com/TheAiSingularity/graphrag-local-ollama){:target="_blank"} ï¼šè¼ƒæ—©æœŸçš„æ•™å­¸è³‡æºï¼ŒæŒ‡å°å¦‚ä½•åœ¨åœ°ç«¯ LLM ä¸Šé€²è¡Œ GraphRAG çš„æ‡‰ç”¨ã€‚


ä¸Šè¿°å…©å€‹ repo éƒ½ä¾è³´æ–¼ä¸€å€‹åç‚º ollama çš„å·¥å…·ä¾†å‰µå»ºèˆ‡ OpenAI API ç›¸å®¹çš„æ¥å£ã€‚ollama çš„åº•å±¤æ¶æ§‹æ˜¯åŸºæ–¼ llama\.cppï¼Œä¸¦é€²è¡Œäº†ä¸€äº›èª¿æ•´ï¼Œæœ€çµ‚æä¾›äº†ä¸€å€‹è¼ƒç‚ºä¾¿æ·çš„æ“ä½œä»‹é¢ã€‚ç°¡å–®ä¾†èªªï¼Œollama ä½¿ç”¨ Go èªè¨€åŒ…è£¹äº† llama\.cppï¼Œè®“ä½¿ç”¨è€…å¯ä»¥è¼•é¬†å®‰è£å’Œç®¡ç†æ¨¡å‹ã€‚

ç„¶è€Œï¼Œç”±æ–¼ ollama é€²è¡Œäº†ç‰¹å®šèª¿æ•´ï¼Œå…¶æ‰€å»ºç«‹çš„ä¼ºæœå™¨ç„¡æ³•ç›´æ¥ç”¨æ–¼ Microsoft GraphRAGï¼Œé‚„éœ€è¦ä¿®æ”¹ GraphRAG çš„éƒ¨åˆ†åŸå§‹ç¢¼æ‰èƒ½é‹è¡Œã€‚

å› æ­¤ï¼Œè‹¥å¸Œæœ›æ›´ç›´æ¥åœ°åœ¨åœ°ç«¯å•Ÿå‹• OpenAI API ç›¸å®¹ä¼ºæœå™¨ï¼Œå»ºè­°ç›´æ¥ä½¿ç”¨ llama\.cppï¼Œä½¿ç”¨ llama\.cpp ä¸åƒ…ç°¡å–®ç›´è§€ï¼Œä¹Ÿé¿å…äº†ä¸å¿…è¦çš„ä¸­é–“å±¤ï¼Œå¤§å¹…æå‡éˆæ´»æ€§å’Œæ§åˆ¶æ€§ï¼ŒåŒæ™‚ä¹Ÿèƒ½æ›´æ¸…æ™°åœ°äº†è§£å¦‚ä½•ä½¿ç”¨åœ°ç«¯ LLM ä¾†å–ä»£ OpenAI æˆ– Azure OpenAI çš„ LLMï¼Œä¸¦ç„¡ç¸«åœ°æ•´åˆåˆ° Microsoft GraphRAGã€‚

é€™ç¯‡æ–‡ç« ä¾¿æ˜¯å¸Œæœ›å¸¶å¤§å®¶ä¸€èµ·æ“ä½œï¼Œå¦‚ä½•åœ¨ Microsoft GraphRAG ä¸­ä½¿ç”¨llama\.cpp æ¶è¨­çš„åœ°ç«¯ LLM ä¼ºæœå™¨ï¼Œä¸»è¦æœƒåˆ†æˆå…©æ­¥é©Ÿï¼š

A\. å•Ÿå‹• llama\.cpp ä¼ºæœå™¨
B\. Microsoft GraphRAG
### A\. å•Ÿå‹• llama\.cpp ä¼ºæœå™¨

é€™æ­¥é©Ÿéœ€è¦å•Ÿå‹• 2 å€‹ä¼ºæœå™¨ï¼Œä¸€å€‹ç”¨æ–¼ completionï¼Œå¦ä¸€å€‹ç”¨æ–¼ embeddingï¼Œæ¶è¨­ä¼ºæœå™¨çš„ç´°ç¯€å¯ä»¥åƒè€ƒæˆ‘ä¹‹å‰çš„ [æ–‡ç« ](../2451807f8ba5/) ï¼Œé€™é‚Šå¸¶å¤§å®¶å¿«é€Ÿæ“ä½œã€‚
### A\-1\. clone llama\.cpp å°ˆæ¡ˆ

æŠŠ [llama\.cpp](https://github.com/ggerganov/llama.cpp){:target="_blank"} çš„ repo clone ä¸‹ä¾†
```bash
git clone https://github.com/ggerganov/llama.cpp.git
```
### A\-2\. ä½¿ç”¨ Makefile é€²è¡Œç·¨è­¯

ä½¿ç”¨ `make` å° llama\.cpp å°ˆæ¡ˆé€²è¡Œç·¨è­¯ï¼Œå¦‚æœä½ æœ‰ GPU è¦ä½¿ç”¨ï¼Œéœ€çœ‹ [llama\.cppæ–‡ä»¶](https://github.com/ggerganov/llama.cpp/blob/master/docs/build.md#blas-build){:target="_blank"} æ‰¾åˆ°ç¬¦åˆä½ ç’°å¢ƒçš„æŒ‡ä»¤ã€‚

æˆ‘é€™é‚Šæ˜¯ä½¿ç”¨ CUDAï¼Œå› æ­¤åŠ ä¸Š `GGML_CUDA=1` ã€‚
```bash
make GGML_CUDA=1 # çœ‹ä½ çš„ç’°å¢ƒç‚ºä½•
```
### A\-3\. æº–å‚™ç’°å¢ƒ

å»ºè­°ä½¿ç”¨ conda ä¾†ç®¡ç†
```lua
conda create --name llamaCpp python=3.9
conda activate llamaCpp
python3 -m pip install -r requirements.txt
```
### A\-4\. è½‰æª”èˆ‡é‡åŒ–æ¨¡å‹

Hugging Face ä¸Šå¯ä»¥ä¸‹è¼‰åˆ°å¾ˆå¤šè½‰æª”æˆ–é‡åŒ–å¾Œçš„ GGUF æ¨¡å‹ï¼Œå»ºè­°å¤§å®¶å¯ä»¥ç›´æ¥ä¸‹è¼‰æ“ä½œï¼Œæˆ‘å°‡ä¸‹è¼‰å¾Œçš„æ¨¡å‹æ”¾åœ¨ \./models/ ä¸­ã€‚

éœ€è¦æ›´å¤šç´°ç¯€çš„æœ‹å‹å¯ä»¥åƒè€ƒä¹‹å‰çš„ [æ–‡ç« ](../2451807f8ba5/) ã€‚
### A\-5\. å•Ÿå‹• Completion API Server

åŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤åœ¨ 8080 port é–‹å•Ÿ Completion API Serverï¼Œä½ å¯ä»¥åœ¨ http://127\.0\.0\.1:8080 çœ‹åˆ°å•Ÿå‹•çš„ Serverã€‚
```css
./llama-server --host 0.0.0.0 --port 8080 \
  --threads 8 \
  --parallel 1 \
  --gpu-layers 999 \
  --ctx-size 0 \
  --n-predict -1 \
  --defrag-thold 1 \
  --model ./models/qwen2-7b-instruct-fp16.gguf
```
### A\-6\. å•Ÿå‹• Embeddings API Server

æ¥è‘—åŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤åœ¨ 8081 port é–‹å•Ÿ Embeddings API Serverï¼Œä½ å¯ä»¥æ‰¾ä½ å–œæ­¡çš„ Embeddings æ¨¡å‹ï¼Œä¸éè¨˜å¾— [llama\.cpp çš„ GitHub](https://github.com/ggerganov/llama.cpp){:target="_blank"} çœ‹ä¸‹ç¾åœ¨æ”¯æ´çš„é …ç›®ï¼Œ å¦‚æœ€è¿‘å¾ˆç´…çš„ jina\-embeddings\-v3ï¼Œllama\.cpp ä¾¿é‚„æ²’æ”¯æ´ã€‚
```css
./llama-server --host 0.0.0.0 --port 8081 \
  --threads 8 \
  --parallel 1 \
  --gpu-layers 999 \
  --ctx-size 0 \
  --n-predict -1 \
  --defrag-thold 1 \
  --embeddings \
  --pooling mean \
  --batch-size 8192 \
  --ubatch-size 4096 \
  --model ./models/qwen2-7b-instruct-fp16.gguf
```

å¦‚æ­¤ä¾¿æ¶è¨­å¥½ 2 å€‹ API serverï¼Œå•Ÿå‹•æ™‚éœ€èŠ±é»æ™‚é–“ï¼Œç¢ºå®šå®Œæˆå¾Œä¾¿å¯ç¹¼çºŒä¸‹é¢çš„æ­¥é©Ÿã€‚
### B\. Microsoft GraphRAG

å•Ÿå‹•å¥½ä¼ºæœå™¨å¾Œï¼Œæˆ‘å€‘æ¥è‘—è¦ä¾†ä½¿ç”¨ Microsoft GraphRAGï¼Œå° Microsoft GraphRAG ä¸ç†Ÿæˆ–æƒ³çœ‹æ›´å¤šç´°ç¯€å¯ä»¥åƒè€ƒæˆ‘ä¹‹å‰çš„ [æ–‡ç« ](../ac07991855e6/) ï¼Œé€™é‚Šä¸€æ¨£å¸¶å¤§å®¶å¿«é€Ÿæ“ä½œã€‚
### B\-1\. ç’°å¢ƒè¨­ç½®

ç‰ˆæœ¬è¦æ±‚æ˜¯ Python 3\.10 åˆ° 3\.12ï¼Œæˆ‘ä½¿ç”¨ conda å»ºç«‹ç’°å¢ƒã€‚
```lua
conda create -n GraphRAG python=3.10
conda activate GraphRAG
pip install graphrag
```
### B\-2\. æº–å‚™è³‡æ–™å¤¾èˆ‡æ–‡ä»¶

æˆ‘å€‘å°‡å®˜æ–¹çš„åƒè€ƒæ–‡ä»¶ä¸‹è¼‰ä¸‹ä¾†ã€‚
```bash
mkdir -p ./ragtest/input
curl https://www.gutenberg.org/cache/epub/24022/pg24022.txt > ./ragtest/input/book.txt
```
### B\-3\. Workspace åˆå§‹åŒ–è¨­ç½®
```bash
python -m graphrag.index --init --root ./ragtest
```
### B\-4\. ä¿®æ”¹ settings\.yaml

æ¥è‘—ä¿®æ”¹ \./ragtest/settings\.yamlï¼Œå°‡å‰é¢ llama\.cpp å•Ÿå‹•çš„ Completion API Server èˆ‡ Embeddings API Server çš„ API è·¯å¾‘è¼¸å…¥åœ¨é€™é‚Šï¼Œç”¨ä»¥å–ä»£ OpenAI APIã€‚
```yaml
llm:
  api_key: ${GRAPHRAG_API_KEY}
  type: openai_chat # or azure_openai_chat
  model: qwen2-7b-instruct
  model_supports_json: true # recommended if this is available for your model.
  max_tokens: 512
  # request_timeout: 180.0
  api_base: http://localhost:8080
  api_version: v1

embeddings:
  ## parallelization: override the global parallelization settings for embeddings
  async_mode: threaded # or asyncio
  llm:
    api_key: ${GRAPHRAG_API_KEY}
    type: openai_embedding # or azure_openai_embedding
    model: qwen2-7b-instruct
    api_base: http://localhost:8081
    api_version: v1
```
### B\-5\. åŸ·è¡Œ Indexing pipeline

ä¿®å¥½å®Œå¾Œå°±å¯ä»¥åŸ·è¡Œä»¥ä¸‹æŒ‡ä»¤ï¼Œé–‹å§‹é€²è¡Œ Indexing pipelineã€‚
```bash
python -m graphrag.index --root ./ragtest
```

å¤§ç´„æœƒè·‘ 1 å°æ™‚å·¦å³ï¼Œä¸»è¦çœ‹ä½ çš„ input\.txt å¤§å°èˆ‡é›»è…¦é€Ÿåº¦ï¼Œé€™æ­¥é©Ÿå¯èƒ½æœƒé‡åˆ°å•é¡Œï¼Œæˆ‘è’é›†äº†ä¸€äº›æˆ‘é‡åˆ°ä»¥åŠå¸¸è¦‹çš„å•é¡Œæ”¾åœ¨ä¸‹é¢ï¼Œå¦‚æœä½ ä¹Ÿé‡åˆ°å¯ä»¥è©¦è©¦çœ‹ã€‚

éƒ½é †åˆ©é‹è¡Œå®Œæˆå¾Œï¼Œæœƒçœ‹åˆ°ï¼šğŸš€ ALL workflows completed successfully
### B\-6\. é€²è¡Œå•ç­”

ä½¿ç”¨ Global Search çš„æ–¹å¼æå‡ºé€²éšå•é¡Œçš„ç¯„ä¾‹ï¼Œå…¶ä»–æ–¹å¼è«‹åƒè€ƒ [å®˜æ–¹æ–‡ä»¶](https://microsoft.github.io/graphrag/posts/query/overview/){:target="_blank"} ã€‚ï¼š
```css
python -m graphrag.query \
--root ./ragtest \
--method global \
"What are the top themes in this story?"
```
### å¸¸è¦‹å•é¡Œï¼š

1\. âŒcreate\_base\_entity\_graph

æœ€å¸¸è¦‹çš„å•é¡Œï¼Œå¤§å¤šå¯é€éä¿®æ”¹ \./ragtest/settings\.yaml ä¸­çš„ llm çš„ `max_tokens` èˆ‡ chunks çš„ `size` å’Œ `overlap` è§£æ±ºã€‚

æœ‰æ™‚å€™æ¨¡å‹å£“ç¸®å¤ªå¤šï¼Œæœƒå½±éŸ¿åˆ°æ¨¡å‹è·Ÿéš¨æŒ‡ä»¤çš„èƒ½åŠ›ï¼Œä¹Ÿæœƒå‡ºç¾é€™å€‹å•é¡Œï¼Œé€™æ™‚å¯ä»¥æ›åˆ¥çš„æ¨¡å‹å†æ¸¬è©¦ã€‚

ç´°ç¯€åƒè€ƒï¼šGithub [Issue437](https://github.com/microsoft/graphrag/issues/437){:target="_blank"} ã€ [Issue951](https://github.com/microsoft/graphrag/issues/951){:target="_blank"}
```yaml
llm:
  max_tokens: 512

chunks:
  size: 600
  overlap: 150
```

2\. ValueError\(â€œColumns must be same length as keyâ€\)

å¦‚æœæŸ¥çœ‹ logs ä¸­çš„æœ‰é€™å€‹å•é¡Œï¼Œä¸€æ¨£ä¹Ÿæ˜¯å¯ä»¥é€éä¿®æ”¹ chunks ä¾†ä¿®æ­£
```yaml
chunks:
  size: 600
  overlap: 150
```

ç´°ç¯€åƒè€ƒï¼šGithub [Issue362](https://github.com/microsoft/graphrag/issues/362){:target="_blank"}

3\. âŒcreate\_final\_community\_reports

é€™é€™æ­¥é©Ÿéœ€è¦ Context window æ¯”è¼ƒé•·çš„ LLMï¼Œå› æ­¤è‹¥ä½ æ˜¯ä½¿ç”¨ llama3\.1 ï¼Œæœƒç„¡æ³•å®Œæˆé€™æ­¥é©Ÿï¼Œå› ç‚º llama3\.1 çš„ context window åªæœ‰ 8kã€‚

ç´°ç¯€åƒè€ƒï¼šGithub [Issue374](https://github.com/microsoft/graphrag/issues/374){:target="_blank"}
### æ”¯æŒé¼“å‹µ

å¦‚æœæ–‡ç« å°ä½ æœ‰å¹«åŠ©ï¼Œæˆ–é¡˜æ„é¼“å‹µæˆ‘æŒçºŒå‰µä½œï¼Œå¯ä»¥å¹«æ–‡ç« æ‹æ‰‹ï¼Œæˆ–é»æ“Šä¸‹æ–¹é€£çµè«‹æˆ‘å–ä¸€æ¯å’–å•¡ï¼Œæ„Ÿè¬æ”¯æŒ\!


![](/assets/895bb92b0c08/1*QCQqlZr6doDP-cszzpaSpw.png)




_[Post](https://medium.com/@cch.chichieh/local-graphrag-llama-cpp-%E4%BD%BF%E7%94%A8%E5%9C%B0%E7%AB%AF-llm-895bb92b0c08){:target="_blank"} converted from Medium by [ZMediumToMarkdown](https://github.com/ZhgChgLi/ZMediumToMarkdown){:target="_blank"}._
