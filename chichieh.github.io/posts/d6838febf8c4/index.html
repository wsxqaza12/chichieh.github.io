<!doctype html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="RAG實作教學，LangChain + Llama2 創造你的個人LLM" /><meta name="author" content="ChiChieh Huang" /><meta property="og:locale" content="en" /><meta name="description" content="在這篇文章中，我們將帶你使用 LangChain + Llama2，一步一步架設自己的 RAG（Retrieval-Augmented Generation）的系統，讓你可以上傳自己的 PDF，並且詢問 LLM 關於 PDF 的訊息。" /><meta property="og:description" content="在這篇文章中，我們將帶你使用 LangChain + Llama2，一步一步架設自己的 RAG（Retrieval-Augmented Generation）的系統，讓你可以上傳自己的 PDF，並且詢問 LLM 關於 PDF 的訊息。" /><link rel="canonical" href="https://chichieh-huang.com/posts/d6838febf8c4/" /><meta property="og:url" content="https://chichieh-huang.com/posts/d6838febf8c4/" /><meta property="og:site_name" content="ChiChieh Huang" /><meta property="og:image" content="https://chichieh-huang.com/assets/d6838febf8c4/1*BKiZCXCL9A4_9dthYFBGeg.png" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2024-01-21T03:08:40+08:00" /><meta name="twitter:card" content="summary_large_image" /><meta property="twitter:image" content="https://chichieh-huang.com/assets/d6838febf8c4/1*BKiZCXCL9A4_9dthYFBGeg.png" /><meta property="twitter:title" content="RAG實作教學，LangChain + Llama2 創造你的個人LLM" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"ChiChieh Huang","url":"https://medium.com/@cch.chichieh"},"dateModified":"2025-03-11T03:26:07+08:00","datePublished":"2024-01-21T03:08:40+08:00","description":"在這篇文章中，我們將帶你使用 LangChain + Llama2，一步一步架設自己的 RAG（Retrieval-Augmented Generation）的系統，讓你可以上傳自己的 PDF，並且詢問 LLM 關於 PDF 的訊息。","headline":"RAG實作教學，LangChain + Llama2 創造你的個人LLM","image":"https://chichieh-huang.com/assets/d6838febf8c4/1*BKiZCXCL9A4_9dthYFBGeg.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://chichieh-huang.com/posts/d6838febf8c4/"},"url":"https://chichieh-huang.com/posts/d6838febf8c4/"}</script><title>RAG實作教學，LangChain + Llama2 |創造你的個人LLM | ChiChieh Huang</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="ChiChieh Huang"><meta name="application-name" content="ChiChieh Huang"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.32.2/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/glightbox@3.3.0/dist/css/glightbox.min.css"> <script src="/assets/js/dist/theme.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/glightbox@3.3.0/dist/js/glightbox.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.13/dayjs.min.js,npm/dayjs@1.11.13/locale/en.js,npm/dayjs@1.11.13/plugin/relativeTime.js,npm/dayjs@1.11.13/plugin/localizedFormat.js,npm/tocbot@4.32.2/dist/tocbot.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/app.min.js?baseurl=&register=true" ></script><body><aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end"><header class="profile-wrapper"> <a href="/" id="avatar" class="rounded-circle"><img src="/assets/img/avatar.png" width="112" height="112" alt="avatar" onerror="this.style.display='none'"></a> <a class="site-title d-block" href="/">ChiChieh Huang</a><p class="site-subtitle fst-italic mb-0"><div class="medium-followers-container"> <a href="https://medium.com/@cch.chichieh" target="_blank" class="medium-link"> <span class="followers-count">880+ followers on&nbsp;</span> <svg class="medium-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M13 12C13 15.3137 10.3137 18 7 18C3.68629 18 1 15.3137 1 12C1 8.68629 3.68629 6 7 6C10.3137 6 13 8.68629 13 12Z"/><path d="M23 12C23 14.7614 22.5523 17 22 17C21.4477 17 21 14.7614 21 12C21 9.23858 21.4477 7 22 7C22.5523 7 23 9.23858 23 12Z"/><path d="M17 12C17 14.7614 16.5523 17 16 17C15.4477 17 15 14.7614 15 12C15 9.23858 15.4477 7 16 7C16.5523 7 17 9.23858 17 12Z"/> </svg> <span>Medium</span> </a></div>Hi~ 我專注於 Generative AI 產品開發，熱愛桌球與奇幻小說，並希望透過中文內容與更多人分享 AI 知識，讓技術更貼近社群。</p></header><nav class="flex-column flex-grow-1 w-100 ps-0"><ul class="nav"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle"></i> <span>ABOUT</span> </a></ul></nav><div class="sidebar-bottom d-flex flex-wrap align-items-center w-100"> <button type="button" class="btn btn-link nav-link" aria-label="Switch Mode" id="mode-toggle"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/wsxqaza12" aria-label="github" target="_blank" rel="noopener noreferrer" > <i class="fab fa-github"></i> </a> <a href="" aria-label="linkedin" target="_blank" rel="noopener noreferrer" > <i class="fab fa-linkedin"></i> </a> <a href="javascript:location.href = 'mailto:' + ['cch.chichieh','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></aside><div id="main-wrapper" class="d-flex justify-content-center"><div class="container d-flex flex-column px-xxl-5"><header id="topbar-wrapper" class="flex-shrink-0" aria-label="Top Bar"><div id="topbar" class="d-flex align-items-center justify-content-between px-lg-3 h-100" ><nav id="breadcrumb" aria-label="Breadcrumb"> <span> <a href="/">Home</a> </span> <span>RAG實作教學，LangChain + Llama2 |創造你的個人LLM</span></nav><button type="button" id="sidebar-trigger" class="btn btn-link" aria-label="Sidebar"> <i class="fas fa-bars fa-fw"></i> </button><div id="topbar-title"> Post</div><button type="button" id="search-trigger" class="btn btn-link" aria-label="Search"> <i class="fas fa-search fa-fw"></i> </button> <search id="search" class="align-items-center ms-3 ms-lg-0"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..." > </search> <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button></div></header><div class="row flex-grow-1"><main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4"><article class="px-1" data-toc="true"><header><h1 data-toc-skip>RAG實作教學，LangChain + Llama2 |創造你的個人LLM</h1><p class="post-desc fw-light mb-4">在這篇文章中，我們將帶你使用 LangChain + Llama2，一步一步架設自己的 RAG（Retrieval-Augmented Generation）的系統，讓你可以上傳自己的 PDF，並且詢問 LLM 關於 PDF 的訊息。</p><div class="post-meta text-muted"> <span> Posted <time data-ts="1705777720" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > Jan 21, 2024 </time> </span> <span> Updated <time data-ts="1741634767" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > Mar 10, 2025 </time> </span><div class="mt-3 mb-3"> <a href="/assets/d6838febf8c4/1*BKiZCXCL9A4_9dthYFBGeg.png" class="popup img-link preview-img shimmer"><img src="/assets/d6838febf8c4/1*BKiZCXCL9A4_9dthYFBGeg.png" alt="Preview Image" width="1200" height="630" loading="lazy"></a></div><div class="d-flex justify-content-between"> <span> By <em> <a href="https://medium.com/@cch.chichieh">ChiChieh Huang</a> </em> </span><div> <span class="readtime" data-bs-toggle="tooltip" data-bs-placement="bottom" title="1971 words" > <em>10 min</em> read</span></div></div></div></header><div id="toc-bar" class="d-flex align-items-center justify-content-between invisible"> <span class="label text-truncate">RAG實作教學，LangChain + Llama2 |創造你的個人LLM</span> <button type="button" class="toc-trigger btn me-1"> <i class="fa-solid fa-list-ul fa-fw"></i> </button></div><button id="toc-solo-trigger" type="button" class="toc-trigger btn btn-outline-secondary btn-sm"> <span class="label ps-2 pe-1">Contents</span> <i class="fa-solid fa-angle-right fa-fw"></i> </button> <dialog id="toc-popup" class="p-0"><div class="header d-flex flex-row align-items-center justify-content-between"><div class="label text-truncate py-2 ms-4">RAG實作教學，LangChain + Llama2 |創造你的個人LLM</div><button id="toc-popup-close" type="button" class="btn mx-1 my-1 opacity-75"> <i class="fas fa-close"></i> </button></div><div id="toc-popup-content" class="px-4 py-3 pb-4"></div></dialog><div class="content"><h3 id="rag實作教學langchain--llama2-創造你的個人llm"><span class="me-2">RAG實作教學，LangChain + Llama2 |創造你的個人LLM</span><a href="#rag實作教學langchain--llama2-創造你的個人llm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="/assets/d6838febf8c4/1*BKiZCXCL9A4_9dthYFBGeg.png" class="popup img-link shimmer"><img src="/assets/d6838febf8c4/1*BKiZCXCL9A4_9dthYFBGeg.png" alt="RAG 服務範例" loading="lazy"></a></p><p>RAG 服務範例</p><p>在這篇文章中，會帶你一步一步架設自己的 RAG（Retrieval-Augmented Generation）系統，讓你可以上傳自己的 PDF，並且詢問 LLM 關於 PDF 的訊息，這篇教學注重在上圖藍底色的部份，也就是先不接 Gradio (想看接好的可以參考 <a href="../c7d1dac2494e/">下篇</a> )。相關的 tech stack 有以下幾個：</p><ol><li><strong>LLM</strong> : Llama2<li>LLM API: llama.cpp service<li>Langchain<li><strong>Vector DB</strong> : ChromaDB<li><strong>Embeding</strong> : sentence-Tranformers</ol><p>其中的核心在於 Langchain，它是用於開發由語言模型支援的應用程式的框架，LangChain 就像膠水一樣，有各種接口可以將 LLM 模型與其他工具和數據源連接，不過現在 LangChain 正在蓬勃發展中，許多文件或 API 改版很多，以下我使用最簡單的方式示範。</p><h3 id="步驟1-環境設置"><span class="me-2">步驟1. 環境設置</span><a href="#步驟1-環境設置" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>首先設置 python 環境，我使用 conda 創建環境，並安裝以下 library，我在 Jupyter 環境完成範例，完整 code 可以在 <a href="https://github.com/wsxqaza12/RAG_example" target="_blank">github</a> 找到。</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="c1"># python=3.9
</span><span class="n">ipykernel</span>
<span class="n">ipywidgets</span>
<span class="n">langchain</span>
<span class="n">PyMuPDF</span>
<span class="n">chromadb</span>
<span class="n">sentence</span><span class="o">-</span><span class="n">transformers</span>
<span class="n">llama</span><span class="o">-</span><span class="n">cpp</span><span class="o">-</span><span class="n">python</span>
</pre></table></code></div></div><h3 id="步驟2-讀入檔案處理並匯入-db"><span class="me-2">步驟2. 讀入檔案處理並匯入 DB</span><a href="#步驟2-讀入檔案處理並匯入-db" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="/assets/d6838febf8c4/1*pvD0sDAZyrI8w_Tyw2FdCQ.png" class="popup img-link shimmer"><img src="/assets/d6838febf8c4/1*pvD0sDAZyrI8w_Tyw2FdCQ.png" alt="" loading="lazy"></a></p><p>首先我們要將外部資訊處理後，放到 DB 中，以供之後查詢相關知識，這邊的步驟對應到上圖框起來的部分，也就是橘色的 1. Text splitter 與 2. Embedding</p><h3 id="a--使用文件載入器"><span class="me-2">a) . 使用文件載入器</span><a href="#a--使用文件載入器" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Langchain 提供了很多文件載入器，總計大概有 55 種，包含 word, csv, PDF, GoogleDrive, Youtube 等，使用方式也很簡單，這邊我創建了一個虛擬人物 Alison Hawk 的 PDF 資訊，並使用 <code class="language-plaintext highlighter-rouge">PyMuPDFLoader</code> 讀入，Alison Hawk 的PDF 資訊可以在 <a href="https://github.com/wsxqaza12/RAG_example/blob/master/Virtual_characters.pdf" target="_blank">github</a> 查看。注意 PyMuPDFLoader 需要安裝 <code class="language-plaintext highlighter-rouge">PyMuPDF</code> 才能使用。</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">langchain.document_loaders</span> <span class="kn">import</span> <span class="n">PyMuPDFLoader</span>
<span class="n">loader</span> <span class="o">=</span> <span class="nc">PyMuPDFLoader</span><span class="p">(</span><span class="sh">"</span><span class="s">LangChain/Virtual_characters.pdf</span><span class="sh">"</span><span class="p">)</span>
<span class="n">PDF_data</span> <span class="o">=</span> <span class="n">loader</span><span class="p">.</span><span class="nf">load</span><span class="p">()</span>
</pre></table></code></div></div><h3 id="b--使用-text-splitter-分割文件"><span class="me-2">b) . 使用 Text splitter 分割文件</span><a href="#b--使用-text-splitter-分割文件" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Text splitter 會將文件或文字分割成一個個 chunk，用以預防文件的資訊超過 LLM 的 tokens，有一些研究在探討如何將 chunk 優化，可以參考我的另一篇 <a href="../fced76fdb8b9/">文章</a> 。</p><p>這步驟常用的工具 <code class="language-plaintext highlighter-rouge">RecursiveCharacterTextSplitter</code> 與 <code class="language-plaintext highlighter-rouge">CharacterTextSplitter</code> ，差別在於 <code class="language-plaintext highlighter-rouge">RecursiveCharacterTextSplitter</code> 如果區塊大小超過指定閾值，它也會遞歸地將文字分割成更小的區塊。LangChain 2種方式皆有提供，另外主要參數為以下：</p><ul><li>chunk_size：決定分割文字時每個區塊中的最大字元數。它指定每個區塊的大小或長度。<li>chunk_overlap：決定分割文字時連續區塊之間重疊的字元數。它指定前一個區塊的多少應包含在下一個區塊中。</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">langchain.text_splitter</span> <span class="kn">import</span> <span class="n">RecursiveCharacterTextSplitter</span>
<span class="n">text_splitter</span> <span class="o">=</span> <span class="nc">RecursiveCharacterTextSplitter</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">5</span><span class="p">)</span>
<span class="n">all_splits</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="p">.</span><span class="nf">split_documents</span><span class="p">(</span><span class="n">PDF_data</span><span class="p">)</span>
</pre></table></code></div></div><h3 id="c--載入-embedding-model"><span class="me-2">c) . 載入 Embedding model</span><a href="#c--載入-embedding-model" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>接著使用 Embedding 將步驟 b)分割的 chunk 文字轉換為向量，LangChain 提供了許多 Embedding model 的接口，如OpenAI、Cohere、Hugging Face、Weaviate 等，可以參考 <a href="https://python.langchain.com/docs/modules/data_connection/text_embedding/" target="_blank">LangChain官網</a> 。</p><p>這邊我使用 Hugging Face 的 Sentence Transformers，它提供了許多種 pretrain 模型，可以根據你的需求或應用情境選擇，我選擇 <code class="language-plaintext highlighter-rouge">all-MiniLM-L6-v2</code> ，其他 model 細節可以看到 <a href="https://www.sbert.net/docs/pretrained_models.html" target="_blank">SBERT.net</a> 或 <a href="https://huggingface.co/sentence-transformers" target="_blank">HuggingFace</a> 。注意要先安裝 <code class="language-plaintext highlighter-rouge">sentence-Tranformers</code> 才能使用。</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">langchain.embeddings</span> <span class="kn">import</span> <span class="n">HuggingFaceEmbeddings</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="sh">"</span><span class="s">sentence-transformers/all-MiniLM-L6-v2</span><span class="sh">"</span>
<span class="n">model_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="sh">'</span><span class="s">device</span><span class="sh">'</span><span class="p">:</span> <span class="sh">'</span><span class="s">cpu</span><span class="sh">'</span><span class="p">}</span>
<span class="n">embedding</span> <span class="o">=</span> <span class="nc">HuggingFaceEmbeddings</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model_name</span><span class="p">,</span>
                                  <span class="n">model_kwargs</span><span class="o">=</span><span class="n">model_kwargs</span><span class="p">)</span>
</pre></table></code></div></div><h3 id="d--將-embedding-結果匯入-vectordb"><span class="me-2">d) . 將 Embedding 結果匯入 VectorDB</span><a href="#d--將-embedding-結果匯入-vectordb" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Embedding 後的結果我們會儲存在 VectorDB 中，常見的 VectorDB 有 Chroma、Pinecone、FAISS等，這邊我使用 Chroma 來實作。Chroma 跟 LangChain 的整合得很好，可以直接使用 LangChain 的接口來做。</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
</pre><td class="rouge-code"><pre><span class="c1"># Embed and store the texts
# Supplying a persist_directory will store the embeddings on disk
</span><span class="kn">from</span> <span class="n">langchain.vectorstores</span> <span class="kn">import</span> <span class="n">Chroma</span>
<span class="n">persist_directory</span> <span class="o">=</span> <span class="sh">'</span><span class="s">db</span><span class="sh">'</span>
<span class="n">vectordb</span> <span class="o">=</span> <span class="n">Chroma</span><span class="p">.</span><span class="nf">from_documents</span><span class="p">(</span><span class="n">documents</span><span class="o">=</span><span class="n">all_splits</span><span class="p">,</span> <span class="n">embedding</span><span class="o">=</span><span class="n">embedding</span><span class="p">,</span> <span class="n">persist_directory</span><span class="o">=</span><span class="n">persist_directory</span><span class="p">)</span>
</pre></table></code></div></div><h3 id="步驟3-啟用-llm-服務"><span class="me-2">步驟3. 啟用 LLM 服務</span><a href="#步驟3-啟用-llm-服務" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="/assets/d6838febf8c4/1*BhMBZnuZOOJtK310fgUvxw.png" class="popup img-link shimmer"><img src="/assets/d6838febf8c4/1*BhMBZnuZOOJtK310fgUvxw.png" alt="" loading="lazy"></a></p><p>有兩種方法啟動你的 LLM 模型並連接到 LangChain。一是使用 LangChain 的 LlamaCpp 接口來實作，這時候是由 LangChain 幫你把 llama2 服務啟動；另一個方法是用其他方式架設 Llama2 的 API 服務，例如使用 llama.cpp 的 server 啟動 API 服務等，這部分細節可以看到我的另一篇 <a href="../2451807f8ba5/">llama.cpp教學</a> 。我 2 個方式都會示範，你可以選擇適合你的方案。</p><h3 id="a--使用-langchain-的-llamacpp"><span class="me-2">a) . 使用 LangChain 的 LlamaCpp</span><a href="#a--使用-langchain-的-llamacpp" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>使用 LlamaCpp 接口載入 model，它會幫你啟動 Llama 的服務，這方法較簡單，直接使用下面 code 就可以執行，model_path 指定到你的模型中，例子中我使用量化過後的 Llama2 Chat。注意這邊要安裝 <code class="language-plaintext highlighter-rouge">llama-cpp-python</code></p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">langchain.callbacks.manager</span> <span class="kn">import</span> <span class="n">CallbackManager</span>
<span class="kn">from</span> <span class="n">langchain.callbacks.streaming_stdout</span> <span class="kn">import</span> <span class="n">StreamingStdOutCallbackHandler</span>
<span class="kn">from</span> <span class="n">langchain_community.llms</span> <span class="kn">import</span> <span class="n">LlamaCpp</span>
<span class="n">model_path</span> <span class="o">=</span> <span class="sh">"</span><span class="s">llama.cpp/models/llama-2-7b-chat/llama-2_q4.gguf</span><span class="sh">"</span>

<span class="n">llm</span> <span class="o">=</span> <span class="nc">LlamaCpp</span><span class="p">(</span>
    <span class="n">model_path</span><span class="o">=</span><span class="n">model_path</span><span class="p">,</span>
    <span class="n">n_gpu_layers</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">n_batch</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span>
    <span class="n">n_ctx</span><span class="o">=</span><span class="mi">2048</span><span class="p">,</span>
    <span class="n">f16_kv</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
    <span class="n">callback_manager</span><span class="o">=</span><span class="nc">CallbackManager</span><span class="p">([</span><span class="nc">StreamingStdOutCallbackHandler</span><span class="p">()]),</span>
    <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span>
<span class="p">)</span>
</pre></table></code></div></div><p><a href="/assets/d6838febf8c4/1*rk_msRiNOe-wTq6d0ntvpw.png" class="popup img-link shimmer"><img src="/assets/d6838febf8c4/1*rk_msRiNOe-wTq6d0ntvpw.png" alt="" loading="lazy"></a></p><p>可以使用測試看看有沒有 llm 服務啟動沒：</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="nf">llm</span><span class="p">(</span><span class="sh">"</span><span class="s">What is Taiwan known for?</span><span class="sh">"</span><span class="p">)</span>
</pre></table></code></div></div><p><a href="/assets/d6838febf8c4/1*ak-hfiup7IEv6tVZujz10A.png" class="popup img-link shimmer"><img src="/assets/d6838febf8c4/1*ak-hfiup7IEv6tVZujz10A.png" alt="" loading="lazy"></a></p><h3 id="b--使用已架設的-api-服務"><span class="me-2">b) . 使用已架設的 API 服務</span><a href="#b--使用已架設的-api-服務" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>如果你已經使用其他方式架設 LLM 的 API 服務，或者是使用 openai 的 API 的話，你需要使用 LangChain 的 ChatOpenAI 接口。我這邊示範是 llama.cpp 的 server 服務 ( <a href="../2451807f8ba5/">llama.cpp教學</a> )，它提供了類別OpenAI的API，因此我們能直接用同個接口來操作，以下是該接口的一些相關參數：</p><ul><li><strong>open_ai_key</strong> ：由於並沒有使用真正的 OpenAI API，因此可以隨意填寫。<li><strong>openai_api_base</strong> ：為模型API的Base URL<li><strong>max_tokens：</strong> 規範模型回答的長度</ul><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">langchain.chat_models</span> <span class="kn">import</span> <span class="n">ChatOpenAI</span>
<span class="n">llm</span> <span class="o">=</span> <span class="nc">ChatOpenAI</span><span class="p">(</span><span class="n">openai_api_key</span><span class="o">=</span><span class="sh">'</span><span class="s">None</span><span class="sh">'</span><span class="p">,</span> <span class="n">openai_api_base</span><span class="o">=</span><span class="sh">'</span><span class="s">http://127.0.0.1:8080/v1</span><span class="sh">'</span><span class="p">)</span>
</pre></table></code></div></div><h3 id="步驟4-設定你的-prompt"><span class="me-2">步驟4. 設定你的 Prompt</span><a href="#步驟4-設定你的-prompt" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>一些 LLM 可以使用特定的 Prompt。例如，Llama 可使用特殊 token，細節可以參考 <a href="https://twitter.com/RLanceMartin/status/1681879318493003776?s=20" target="_blank">twitter</a> 。我們可以使用 ConditionalPromptSelector 根據模型類型設定 Prompt，如以下：</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
</pre><td class="rouge-code"><pre><span class="kn">from</span> <span class="n">langchain.chains</span> <span class="kn">import</span> <span class="n">LLMChain</span>
<span class="kn">from</span> <span class="n">langchain.chains.prompt_selector</span> <span class="kn">import</span> <span class="n">ConditionalPromptSelector</span>
<span class="kn">from</span> <span class="n">langchain.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>

<span class="n">DEFAULT_LLAMA_SEARCH_PROMPT</span> <span class="o">=</span> <span class="nc">PromptTemplate</span><span class="p">(</span>
    <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">question</span><span class="sh">"</span><span class="p">],</span>
    <span class="n">template</span><span class="o">=</span><span class="sh">"""</span><span class="s">&lt;&lt;SYS&gt;&gt; </span><span class="se">\n</span><span class="s"> You are an assistant tasked with improving Google search </span><span class="se">\
</span><span class="s">results. </span><span class="se">\n</span><span class="s"> &lt;&lt;/SYS&gt;&gt; </span><span class="se">\n\n</span><span class="s"> [INST] Generate THREE Google search queries that </span><span class="se">\
</span><span class="s">are similar to this question. The output should be a numbered list of questions </span><span class="se">\
</span><span class="s">and each should have a question mark at the end: </span><span class="se">\n\n</span><span class="s"> {question} [/INST]</span><span class="sh">"""</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">DEFAULT_SEARCH_PROMPT</span> <span class="o">=</span> <span class="nc">PromptTemplate</span><span class="p">(</span>
    <span class="n">input_variables</span><span class="o">=</span><span class="p">[</span><span class="sh">"</span><span class="s">question</span><span class="sh">"</span><span class="p">],</span>
    <span class="n">template</span><span class="o">=</span><span class="sh">"""</span><span class="s">You are an assistant tasked with improving Google search </span><span class="se">\
</span><span class="s">results. Generate THREE Google search queries that are similar to </span><span class="se">\
</span><span class="s">this question. The output should be a numbered list of questions and each </span><span class="se">\
</span><span class="s">should have a question mark at the end: {question}</span><span class="sh">"""</span><span class="p">,</span>
<span class="p">)</span>

<span class="n">QUESTION_PROMPT_SELECTOR</span> <span class="o">=</span> <span class="nc">ConditionalPromptSelector</span><span class="p">(</span>
    <span class="n">default_prompt</span><span class="o">=</span><span class="n">DEFAULT_SEARCH_PROMPT</span><span class="p">,</span>
    <span class="n">conditionals</span><span class="o">=</span><span class="p">[(</span><span class="k">lambda</span> <span class="n">llm</span><span class="p">:</span> <span class="nf">isinstance</span><span class="p">(</span><span class="n">llm</span><span class="p">,</span> <span class="n">LlamaCpp</span><span class="p">),</span> <span class="n">DEFAULT_LLAMA_SEARCH_PROMPT</span><span class="p">)],</span>
<span class="p">)</span>

<span class="n">prompt</span> <span class="o">=</span> <span class="n">QUESTION_PROMPT_SELECTOR</span><span class="p">.</span><span class="nf">get_prompt</span><span class="p">(</span><span class="n">llm</span><span class="p">)</span>
<span class="n">prompt</span>
</pre></table></code></div></div><p>使用 LLMChain 將 prompt 與 llm 接在一起，另外 LangChain 最近的改版使用 <code class="language-plaintext highlighter-rouge">invoke</code> 替代 <code class="language-plaintext highlighter-rouge">run</code> ，當你看到其他文章使用 <code class="language-plaintext highlighter-rouge">run</code> 時可以注意。</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">llm_chain</span> <span class="o">=</span> <span class="nc">LLMChain</span><span class="p">(</span><span class="n">prompt</span><span class="o">=</span><span class="n">prompt</span><span class="p">,</span> <span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">)</span>
<span class="n">question</span> <span class="o">=</span> <span class="sh">"</span><span class="s">What is Taiwan known for?</span><span class="sh">"</span>
<span class="n">llm_chain</span><span class="p">.</span><span class="nf">invoke</span><span class="p">({</span><span class="sh">"</span><span class="s">question</span><span class="sh">"</span><span class="p">:</span> <span class="n">question</span><span class="p">})</span>
</pre></table></code></div></div><p>實機畫面：</p><p><a href="/assets/d6838febf8c4/1*dexT6PX6eGG3MmWaLAMEoQ.png" class="popup img-link shimmer"><img src="/assets/d6838febf8c4/1*dexT6PX6eGG3MmWaLAMEoQ.png" alt="" loading="lazy"></a></p><h3 id="步驟5-text-retrieval--query-llm"><span class="me-2">步驟5. Text Retrieval + Query LLM</span><a href="#步驟5-text-retrieval--query-llm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="/assets/d6838febf8c4/1*MFfdNUmTPsA9EHC3FA77Ow.png" class="popup img-link shimmer"><img src="/assets/d6838febf8c4/1*MFfdNUmTPsA9EHC3FA77Ow.png" alt="" loading="lazy"></a></p><p>上面我們將 PDF 資訊匯入 DB 中，並且啟動了 LLM 服務，接下來我們要將整個 RAG 的步驟串起來：</p><ol><li>User 發來 QA<li>從 DB 中 Text Retrieval<li>結合 QA 與 Text Retrieval 發送給 LLM<li>LLM 根據資訊回答</ol><p>首先我們要先創建 Retriever，它可以根據非結構化QA 返回相應文件，LangChain 提供了很多種方式，也整合進第三方的工具，目前有很多研究在探討如何根據 QA 找尋對應的文件。我這邊使用的是 <a href="https://python.langchain.com/docs/modules/data_connection/retrievers/vectorstore" target="_blank">Vectorstore</a> 的方式，其他種類可以參考 <a href="https://python.langchain.com/docs/modules/data_connection/retrievers/" target="_blank">Retrievers</a> 。</p><p>接著使用 RetrievalQA 結合 Retriever 與 QA 與 llm，注意 <code class="language-plaintext highlighter-rouge">VectorDBQA</code> 的功能已經被棄用，現在都使用 <code class="language-plaintext highlighter-rouge">RetrievalQA</code> ，如果看到別的文章使用可以注意。</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="n">retriever</span> <span class="o">=</span> <span class="n">vectordb</span><span class="p">.</span><span class="nf">as_retriever</span><span class="p">()</span>

<span class="n">qa</span> <span class="o">=</span> <span class="n">RetrievalQA</span><span class="p">.</span><span class="nf">from_chain_type</span><span class="p">(</span>
    <span class="n">llm</span><span class="o">=</span><span class="n">llm</span><span class="p">,</span> 
    <span class="n">chain_type</span><span class="o">=</span><span class="sh">"</span><span class="s">stuff</span><span class="sh">"</span><span class="p">,</span> 
    <span class="n">retriever</span><span class="o">=</span><span class="n">retriever</span><span class="p">,</span> 
    <span class="n">verbose</span><span class="o">=</span><span class="bp">True</span>
<span class="p">)</span>
</pre></table></code></div></div><h3 id="步驟6-使用你的-rag"><span class="me-2">步驟6. 使用你的 RAG</span><a href="#步驟6-使用你的-rag" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>到這裡我們就串好整個 RAG 的流程，接下來我們來問問 Alison Hawk 的訊息(PDF 紀錄的虛擬人物名稱)</p><div class="language-python highlighter-rouge"><div class="code-header"> <span data-label-text="Python"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="n">query</span> <span class="o">=</span> <span class="sh">"</span><span class="s">Tell me about Alison Hawk</span><span class="sh">'</span><span class="s">s career and age</span><span class="sh">"</span>
<span class="n">qa</span><span class="p">.</span><span class="nf">invoke</span><span class="p">(</span><span class="n">query</span><span class="p">)</span>
</pre></table></code></div></div><p><a href="/assets/d6838febf8c4/1*4iAZeoLqBT6TA9wnZBB0EA.png" class="popup img-link shimmer"><img src="/assets/d6838febf8c4/1*4iAZeoLqBT6TA9wnZBB0EA.png" alt="" loading="lazy"></a></p><p>可以看到 LLM 有拿到從 DB 中拿到我們上傳的 Alison Hawk 的 PDF 訊息，並且得知她是一位 28 歲的 researcher。</p><div class="floating-medium-button"> <a href="https://medium.com/@cch.chichieh" target="_blank" class="medium-follow-button"> <svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M13 12C13 15.3137 10.3137 18 7 18C3.68629 18 1 15.3137 1 12C1 8.68629 3.68629 6 7 6C10.3137 6 13 8.68629 13 12Z" fill="currentColor" /><path d="M23 12C23 14.7614 22.5523 17 22 17C21.4477 17 21 14.7614 21 12C21 9.23858 21.4477 7 22 7C22.5523 7 23 9.23858 23 12Z" fill="currentColor" /><path d="M17 12C17 14.7614 16.5523 17 16 17C15.4477 17 15 14.7614 15 12C15 9.23858 15.4477 7 16 7C16.5523 7 17 9.23858 17 12Z" fill="currentColor" /> </svg> Follow me on Medium </a></div><hr /><p><a href="https://www.buymeacoffee.com/chichieh.huang" target="_blank" class="img-link shimmer" ><img src="https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png" alt="Buy Me A Coffee" style="height: 60px !important;width: 217px !important;" loading="lazy"></a></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw me-1"></i> <a href="/categories/rag-%E6%AA%A2%E7%B4%A2%E5%A2%9E%E5%BC%B7%E7%94%9F%E6%88%90/">RAG (檢索增強生成)</a>, <a href="/categories/tutorial/">Tutorial</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw me-1"></i> <a href="/tags/llm/" class="post-tag no-text-decoration" >llm</a> <a href="/tags/langchain/" class="post-tag no-text-decoration" >langchain</a> <a href="/tags/llama-2/" class="post-tag no-text-decoration" >llama-2</a> <a href="/tags/rag/" class="post-tag no-text-decoration" >rag</a> <a href="/tags/%E4%B8%AD%E6%96%87/" class="post-tag no-text-decoration" >中文</a></div><div class=" post-tail-bottom d-flex justify-content-between align-items-center mt-5 pb-2 " ><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper d-flex align-items-center"> <span class="share-label text-muted">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=RAG%E5%AF%A6%E4%BD%9C%E6%95%99%E5%AD%B8%EF%BC%8CLangChain%20+%20Llama2%20%7C%E5%89%B5%E9%80%A0%E4%BD%A0%E7%9A%84%E5%80%8B%E4%BA%BALLM%20-%20ChiChieh%20Huang&url=https%3A%2F%2Fchichieh-huang.com%2Fposts%2Fd6838febf8c4%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Twitter" aria-label="Twitter"> <i class="fa-fw fa-brands fa-square-x-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=RAG%E5%AF%A6%E4%BD%9C%E6%95%99%E5%AD%B8%EF%BC%8CLangChain%20+%20Llama2%20%7C%E5%89%B5%E9%80%A0%E4%BD%A0%E7%9A%84%E5%80%8B%E4%BA%BALLM%20-%20ChiChieh%20Huang&u=https%3A%2F%2Fchichieh-huang.com%2Fposts%2Fd6838febf8c4%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Facebook" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fchichieh-huang.com%2Fposts%2Fd6838febf8c4%2F&text=RAG%E5%AF%A6%E4%BD%9C%E6%95%99%E5%AD%B8%EF%BC%8CLangChain%20+%20Llama2%20%7C%E5%89%B5%E9%80%A0%E4%BD%A0%E7%9A%84%E5%80%8B%E4%BA%BALLM%20-%20ChiChieh%20Huang" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Telegram" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <button id="copy-link" aria-label="Copy link" class="btn small" data-bs-toggle="tooltip" data-bs-placement="top" title="Copy link" data-title-succeed="Link copied successfully!" > <i class="fa-fw fas fa-link pe-none fs-6"></i> </button> </span></div></div></div></article></main><aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 text-muted"><div class="access"><section id="access-lastmod"><h2 class="panel-heading">Recently Updated</h2><ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2"><li class="text-truncate lh-lg"> <a href="/posts/a1d263ce61b4/">Migrating Away From v0 | Switching to Cursor/Windsurf</a><li class="text-truncate lh-lg"> <a href="/posts/5a67f86311d3/">從 v0 搬家 | 改用Cursor/Windsurf 替代</a><li class="text-truncate lh-lg"> <a href="/posts/942b2f15bea4/">我們都在用 AI，但 AI 跟 AI 怎麼溝通？淺談 AI Agent 通訊協定</a><li class="text-truncate lh-lg"> <a href="/posts/a3476af62056/">OpenManus Tutorial: How to Build Your Custom AI Agent in 2025 (Beginner’s Guide)</a><li class="text-truncate lh-lg"> <a href="/posts/d30783070827/">Understanding Reasoning Models & Test-Time Compute: Insights from DeepSeek-R1</a></ul></section><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/%E4%B8%AD%E6%96%87/">中文</a> <a class="post-tag btn btn-outline-primary" href="/tags/llm/">llm</a> <a class="post-tag btn btn-outline-primary" href="/tags/ai/">ai</a> <a class="post-tag btn btn-outline-primary" href="/tags/tutorial/">tutorial</a> <a class="post-tag btn btn-outline-primary" href="/tags/installation/">installation</a> <a class="post-tag btn btn-outline-primary" href="/tags/rag/">rag</a> <a class="post-tag btn btn-outline-primary" href="/tags/research/">research</a> <a class="post-tag btn btn-outline-primary" href="/tags/ai-agent/">ai-agent</a> <a class="post-tag btn btn-outline-primary" href="/tags/artificial-intelligence/">artificial-intelligence</a> <a class="post-tag btn btn-outline-primary" href="/tags/langchain/">langchain</a></div></section></div><div class="toc-border-cover z-3"></div><section id="toc-wrapper" class="invisible position-sticky ps-0 pe-4 pb-4"><h2 class="panel-heading ps-3 pb-2 mb-0">Contents</h2><nav id="toc"></nav></section></aside></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4"><aside id="related-posts" aria-labelledby="related-label"><h3 class="mb-4" id="related-label">Further Reading</h3><nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4"><article class="col"> <a href="/posts/0e4ac8adc6df/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1709807747" data-df="ll" > Mar 7, 2024 </time><h4 class="pt-0 my-2">RAG 優化技巧| 7 大挑戰與解決方式 | 增進你的 LLM</h4><div class="text-muted"><p>儘管 LLM + RAG 的能力已經令人驚嘆，但我們在使用 RAG 優化 LLM 的過程中，還是會遇到了許多挑戰與難題，包括但不限於檢索器返回不準確或不相關的資料，以及LLM基於錯誤或過時資訊生成答案的情況，因此本文旨在提出 RAG 常見的 7 大挑戰，與其各自的優化方案。</p></div></div></a></article><article class="col"> <a href="/posts/c7d1dac2494e/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1706206252" data-df="ll" > Jan 26, 2024 </time><h4 class="pt-0 my-2">RAG實作教學，Streamlit+LangChain+Llama2</h4><div class="text-muted"><p>我們將重點放在如何使用 Streamlit 來建立一個視覺化的操作介面，以便 Demo 整個RAG（Retrieval-Augmented Generation）的工作流程。</p></div></div></a></article><article class="col"> <a href="/posts/ab70d7117480/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1717580275" data-df="ll" > Jun 5, 2024 </time><h4 class="pt-0 my-2">深入解析 RAG 評估框架：TruLens, RGAR, 與 RAGAs 的比較</h4><div class="text-muted"><p>隨著 RAG 日益發展，有許多 RAG 的變形架構出現，使其成為一個越來越複雜的系統，需要全面性的評估方可監控其效能，提供後續的商業價值。因此，本文旨在探討我們如何全面且廣泛性的評估 RAG 系統，以及 RAG 評估框架的未來方向。</p></div></div></a></article></nav></aside><nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation"> <a href="/posts/fced76fdb8b9/" class="btn btn-outline-primary" aria-label="Older" ><p>RAG (Retrieval Augmented Generation): 為自然語言處理揭開新篇章</p></a> <a href="/posts/c7d1dac2494e/" class="btn btn-outline-primary" aria-label="Newer" ><p>RAG實作教學，Streamlit+LangChain+Llama2</p></a></nav><footer aria-label="Site Info" class=" d-flex flex-column justify-content-center text-muted flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3 " ><p>© <time>2025</time> <a href="https://github.com/wsxqaza12">ChiChieh Huang</a>. <span data-bs-toggle="tooltip" data-bs-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author." >Some rights reserved.</span></p><p>Using the <a data-bs-toggle="tooltip" data-bs-placement="top" title="v7.3.0" href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener" >Chirpy</a> theme for <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>.<br/> Automatically sync posts from Medium with <a href="https://zhgchg.li/posts/en-medium-to-jekyll/" target="_blank">ZhgChg.Li</a>.<br/>Last updated: 2025-06-15 11:02:16 +08:00</p></footer></div></div><div id="search-result-wrapper" class="d-flex justify-content-center d-none"><div class="col-11 content"><div id="search-hints"><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/%E4%B8%AD%E6%96%87/">中文</a> <a class="post-tag btn btn-outline-primary" href="/tags/llm/">llm</a> <a class="post-tag btn btn-outline-primary" href="/tags/ai/">ai</a> <a class="post-tag btn btn-outline-primary" href="/tags/tutorial/">tutorial</a> <a class="post-tag btn btn-outline-primary" href="/tags/installation/">installation</a> <a class="post-tag btn btn-outline-primary" href="/tags/rag/">rag</a> <a class="post-tag btn btn-outline-primary" href="/tags/research/">research</a> <a class="post-tag btn btn-outline-primary" href="/tags/ai-agent/">ai-agent</a> <a class="post-tag btn btn-outline-primary" href="/tags/artificial-intelligence/">artificial-intelligence</a> <a class="post-tag btn btn-outline-primary" href="/tags/langchain/">langchain</a></div></section></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><aside aria-label="Scroll to Top"> <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow"> <i class="fas fa-angle-up"></i> </button></aside></div><div id="mask" class="d-none position-fixed w-100 h-100 z-1"></div><aside id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-bs-animation="true" data-bs-autohide="false" ><div class="toast-header"> <button type="button" class="btn-close ms-auto" data-bs-dismiss="toast" aria-label="Close" ></button></div><div class="toast-body text-center pt-0"><p class="px-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></aside><script> document.addEventListener('DOMContentLoaded', () => { SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<article class="px-1 px-sm-2 px-lg-4 px-xl-0"><header><h2><a href="{url}">{title}</a></h2><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div></header><p>{content}</p></article>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); }); </script>
