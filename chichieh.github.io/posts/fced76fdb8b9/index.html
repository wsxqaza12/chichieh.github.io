<!doctype html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="RAG (Retrieval Augmented Generation): 為自然語言處理揭開新篇章" /><meta name="author" content="ChiChieh Huang" /><meta property="og:locale" content="en" /><meta name="description" content="近期 RAG 的研究發展" /><meta property="og:description" content="近期 RAG 的研究發展" /><link rel="canonical" href="https://chichieh-huang.com/posts/fced76fdb8b9/" /><meta property="og:url" content="https://chichieh-huang.com/posts/fced76fdb8b9/" /><meta property="og:site_name" content="ChiChieh Huang" /><meta property="og:image" content="https://chichieh-huang.com/assets/fced76fdb8b9/0*tSPdWAgLKlOIgTPB.png" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2024-01-17T02:04:07+08:00" /><meta name="twitter:card" content="summary_large_image" /><meta property="twitter:image" content="https://chichieh-huang.com/assets/fced76fdb8b9/0*tSPdWAgLKlOIgTPB.png" /><meta property="twitter:title" content="RAG (Retrieval Augmented Generation): 為自然語言處理揭開新篇章" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"ChiChieh Huang","url":"https://medium.com/@cch.chichieh"},"dateModified":"2025-02-20T18:58:26+08:00","datePublished":"2024-01-17T02:04:07+08:00","description":"近期 RAG 的研究發展","headline":"RAG (Retrieval Augmented Generation): 為自然語言處理揭開新篇章","image":"https://chichieh-huang.com/assets/fced76fdb8b9/0*tSPdWAgLKlOIgTPB.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://chichieh-huang.com/posts/fced76fdb8b9/"},"url":"https://chichieh-huang.com/posts/fced76fdb8b9/"}</script><title>RAG (Retrieval Augmented Generation): 為自然語言處理揭開新篇章 | ChiChieh Huang</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="ChiChieh Huang"><meta name="application-name" content="ChiChieh Huang"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.32.2/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/glightbox@3.3.0/dist/css/glightbox.min.css"> <script src="/assets/js/dist/theme.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/glightbox@3.3.0/dist/js/glightbox.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.13/dayjs.min.js,npm/dayjs@1.11.13/locale/en.js,npm/dayjs@1.11.13/plugin/relativeTime.js,npm/dayjs@1.11.13/plugin/localizedFormat.js,npm/tocbot@4.32.2/dist/tocbot.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/app.min.js?baseurl=&register=true" ></script><body><aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end"><header class="profile-wrapper"> <a href="/" id="avatar" class="rounded-circle"><img src="/assets/img/avatar.png" width="112" height="112" alt="avatar" onerror="this.style.display='none'"></a> <a class="site-title d-block" href="/">ChiChieh Huang</a><p class="site-subtitle fst-italic mb-0"><div class="medium-followers-container"> <a href="https://medium.com/@cch.chichieh" target="_blank" class="medium-link"> <span class="followers-count">880+ followers on&nbsp;</span> <svg class="medium-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M13 12C13 15.3137 10.3137 18 7 18C3.68629 18 1 15.3137 1 12C1 8.68629 3.68629 6 7 6C10.3137 6 13 8.68629 13 12Z"/><path d="M23 12C23 14.7614 22.5523 17 22 17C21.4477 17 21 14.7614 21 12C21 9.23858 21.4477 7 22 7C22.5523 7 23 9.23858 23 12Z"/><path d="M17 12C17 14.7614 16.5523 17 16 17C15.4477 17 15 14.7614 15 12C15 9.23858 15.4477 7 16 7C16.5523 7 17 9.23858 17 12Z"/> </svg> <span>Medium</span> </a></div>Hi~ 我專注於 Generative AI 產品開發，熱愛桌球與奇幻小說，並希望透過中文內容與更多人分享 AI 知識，讓技術更貼近社群。</p></header><nav class="flex-column flex-grow-1 w-100 ps-0"><ul class="nav"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle"></i> <span>ABOUT</span> </a></ul></nav><div class="sidebar-bottom d-flex flex-wrap align-items-center w-100"> <button type="button" class="btn btn-link nav-link" aria-label="Switch Mode" id="mode-toggle"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/wsxqaza12" aria-label="github" target="_blank" rel="noopener noreferrer" > <i class="fab fa-github"></i> </a> <a href="" aria-label="linkedin" target="_blank" rel="noopener noreferrer" > <i class="fab fa-linkedin"></i> </a> <a href="javascript:location.href = 'mailto:' + ['cch.chichieh','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></aside><div id="main-wrapper" class="d-flex justify-content-center"><div class="container d-flex flex-column px-xxl-5"><header id="topbar-wrapper" class="flex-shrink-0" aria-label="Top Bar"><div id="topbar" class="d-flex align-items-center justify-content-between px-lg-3 h-100" ><nav id="breadcrumb" aria-label="Breadcrumb"> <span> <a href="/">Home</a> </span> <span>RAG (Retrieval Augmented Generation): 為自然語言處理揭開新篇章</span></nav><button type="button" id="sidebar-trigger" class="btn btn-link" aria-label="Sidebar"> <i class="fas fa-bars fa-fw"></i> </button><div id="topbar-title"> Post</div><button type="button" id="search-trigger" class="btn btn-link" aria-label="Search"> <i class="fas fa-search fa-fw"></i> </button> <search id="search" class="align-items-center ms-3 ms-lg-0"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..." > </search> <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button></div></header><div class="row flex-grow-1"><main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4"><article class="px-1" data-toc="true"><header><h1 data-toc-skip>RAG (Retrieval Augmented Generation): 為自然語言處理揭開新篇章</h1><p class="post-desc fw-light mb-4">近期 RAG 的研究發展</p><div class="post-meta text-muted"> <span> Posted <time data-ts="1705428247" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > Jan 17, 2024 </time> </span> <span> Updated <time data-ts="1740049106" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > Feb 20, 2025 </time> </span><div class="mt-3 mb-3"> <a href="/assets/fced76fdb8b9/0*tSPdWAgLKlOIgTPB.png" class="popup img-link preview-img shimmer"><img src="/assets/fced76fdb8b9/0*tSPdWAgLKlOIgTPB.png" alt="Preview Image" width="1200" height="630" loading="lazy"></a></div><div class="d-flex justify-content-between"> <span> By <em> <a href="https://medium.com/@cch.chichieh">ChiChieh Huang</a> </em> </span><div> <span class="readtime" data-bs-toggle="tooltip" data-bs-placement="bottom" title="4502 words" > <em>25 min</em> read</span></div></div></div></header><div id="toc-bar" class="d-flex align-items-center justify-content-between invisible"> <span class="label text-truncate">RAG (Retrieval Augmented Generation): 為自然語言處理揭開新篇章</span> <button type="button" class="toc-trigger btn me-1"> <i class="fa-solid fa-list-ul fa-fw"></i> </button></div><button id="toc-solo-trigger" type="button" class="toc-trigger btn btn-outline-secondary btn-sm"> <span class="label ps-2 pe-1">Contents</span> <i class="fa-solid fa-angle-right fa-fw"></i> </button> <dialog id="toc-popup" class="p-0"><div class="header d-flex flex-row align-items-center justify-content-between"><div class="label text-truncate py-2 ms-4">RAG (Retrieval Augmented Generation): 為自然語言處理揭開新篇章</div><button id="toc-popup-close" type="button" class="btn mx-1 my-1 opacity-75"> <i class="fas fa-close"></i> </button></div><div id="toc-popup-content" class="px-4 py-3 pb-4"></div></dialog><div class="content"><h3 id="rag-retrieval-augmented-generation-為自然語言處理揭開新篇章"><span class="me-2">RAG (Retrieval Augmented Generation): 為自然語言處理揭開新篇章</span><a href="#rag-retrieval-augmented-generation-為自然語言處理揭開新篇章" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><h3 id="一-為甚麼要用-rag-"><span class="me-2">一. 為甚麼要用 RAG ?</span><a href="#一-為甚麼要用-rag-" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>如果使用 pretrain 好的 LLM 模型，應用在你個人的情境中，勢必會有些詞不達意的地方，例如問 LLM 你個人的訊息，那麼它會無法回答；這種情況在企業內部也是一樣，例如使用 LLM 來回答企業內部的規章條款等。</p><p>這種時候主要有三種方式來讓 LLM 變得更符合你的需求：</p><ol><li><strong>Promt Enginerring</strong> ： 輸入提示來指導 LLM 產生所需回應。例如常見的 In-context Learning，透過在提示中提供上下文或範例，來形塑模型的回答方式。例如，提供特定回答風格的範例或包含相關的情境資訊，可以引導模型產生更合適的答案。<li><strong>Fine tuning：</strong> 這個過程包括在特定數據集上訓練 LLM，使其回應更符合特定需求。例如，一家公司可能會使用其內部文件 Fine tuning ChatGPT ，使其能夠更準確地回答關於企業內部規章條款等問題。然而，Fine tuning 需要代表性的數據集且量也有一定要求，且 Fine tuning 並不適合於在模型中增加全新的知識，或應對那些需要快速迭代新場景的情況。<li><strong>RAG (Retrieval Augmented Generation)</strong> ： 結合了神經語言模型和擷取系統。擷取系統從資料庫或一組文件中提取相關信息，然後由語言模型使用這些信息來生成回應。可以把 RAG 想像成給模型提供一本教科書，讓它根據特定的問題去找資訊。此方法適用於模型需要整合即時、最新或非常特定的信息非常有用。但RAG 並不適合教會模型理解廣泛的領域或學習新的語言、格式或風格。</ol><p><a href="/assets/fced76fdb8b9/0*tSPdWAgLKlOIgTPB.png" class="popup img-link shimmer"><img src="/assets/fced76fdb8b9/0*tSPdWAgLKlOIgTPB.png" alt="RAG 與方法的比較 Gao, Yunfan et al. “Retrieval-Augmented Generation for Large Language Models: A Survey.” (2023) ." loading="lazy"></a></p><p>RAG 與方法的比較 Gao, Yunfan et al. “Retrieval-Augmented Generation for Large Language Models: A Survey.” (2023) .</p><p>目前的研究已經表明，RAG 在優化 LLM 方面，相較於其他方法具有顯著的優勢 (Shuster et al. , 2021 ; Yasunaga et al. , 2022; Wang et al. , 2023c; Borgeaud et al. , 2022)，主要的優勢可以體現在以下幾點：</p><ol><li>RAG 透過外部知識來提高答案的 <strong>準確性</strong> ，有效地減少了虛假訊息，使得產生的回答更加準確可信。<li>使用擷取技術能夠識別到最新的信息(使用者提供)，這使得 LLM 的回答能保持 <strong>及時性</strong> 。<li>RAG 引用資訊來源是使用者可以核實答案，因此其 <strong>透明透</strong> 非常高，這增強了人們對模型輸出結果的信任。<li>透過擷取與特定領域資料，RAG 能夠為不同領域提供專業的知識支援， <strong>客製化</strong> 能力非常高。<li>在 <strong>安全性和隱私</strong> 管理方面，RAG 透過資料庫來儲存知識，對資料使用有較好控制性。相較之下，經過 Fine tuning 的模型在管理資料存取權限方面不夠明確，容易外洩，這對於企業是一大問題。<li>由於 RAG 不需更新模型參數，因此在處理大規模資料集時， <strong>經濟效率</strong> 方面更具優勢。</ol><p>不過雖然 RAG 有許多優勢在，但這 3 種方法並不是互斥的，反而是相輔相成的。結合 RAG 和 Fine tuning ，甚至 Promt Enginerring 可以讓模型能力的層次性得增強。這種協同作用特別在特定情境下顯得重要，能夠將模型的效能推至最佳。整體過程可能需要經過多次迭代和調整，才能達到最佳的成效。這種迭代過程涵蓋了對模型的持續評估和改進，以滿足特定的應用需求。</p><p><a href="/assets/fced76fdb8b9/1*BRcERCALfqSoRC06ce5b2A.png" class="popup img-link shimmer"><img src="/assets/fced76fdb8b9/1*BRcERCALfqSoRC06ce5b2A.png" alt="RAG 實際應用的過程 Gao, Yunfan et al. “Retrieval-Augmented Generation for Large Language Models: A Survey.” (2023) ." loading="lazy"></a></p><p>RAG 實際應用的過程 Gao, Yunfan et al. “Retrieval-Augmented Generation for Large Language Models: A Survey.” (2023) .</p><h3 id="二-什麼是-rag-"><span class="me-2"><strong>二. 什麼是 RAG ?</strong></span><a href="#二-什麼是-rag-" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>這篇章旨在介紹 RAG 的過程與其使用的相關技術。總結來說 RAG 有兩個關鍵技術：擷取與生成</p><ol><li>擷取(Retrieval)：從大量知識庫中擷取出最相關的前幾個文件<li>生成(Generation)：將擷取到的資訊轉成為自然流暢的文字。</ol><h3 id="擷取retrieval"><span class="me-2">擷取(Retrieval)</span><a href="#擷取retrieval" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>為了使 RAG 技術中的擷取更準確，關鍵在於如何獲得準確的語意空間、匹配查詢和文件的語意空間，以及如何使擷取器的輸出與大型語言模型的偏好相協調，我們在以下分別探討：</p><h3 id="a--如何獲得準確的語意空間"><span class="me-2">a. ) 如何獲得準確的語意空間</span><a href="#a--如何獲得準確的語意空間" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>通常我們會把查詢和文件映射的多維空間，稱之為 <strong>語意空間(semantic space)</strong> ，而進行擷取時，我們是在語意空間中進行，因此若映射的不夠好，那麼對於整個 RAG 系統是個大災難。這邊介紹 2 步建立準確語意空間的方法。</p><ol><li><strong>區塊優化 (Chunk optimization)</strong></ol><p>在處理外部文檔時，首先需要將其拆分成更小的碎塊以提取細粒度特徵，然後將這些特徵嵌入(embedded)以表達其語義。然而，嵌入過大或過小的文本碎塊可能會導致較差的結果，因此需要考慮幾個重要的因素，例如擷取內容的性質、嵌入模型及其最佳塊大小、用戶查詢的預期長度和複雜性，以及具體應用對擷取結果的利用方式。因此目前有許多研究提出多種 <strong>區塊優化</strong> 方法：</p><ol><li><strong>Sliding window technology</strong> ：通過合併跨多個擷取過程的全球相關信息，實現分層擷取。<li><strong>small2big</strong> ：它在初始搜索階段使用小文本塊，然後提供較大的相關文本塊供語言模型處理。<li><strong>Abstract embedding：</strong> 優先考慮基於文檔摘要（或摘要）的前K次擷取，提供對整個文檔內容的全面理解。<li><strong>Metadata Filtering</strong> ：技術透過文件的元資料進行過濾。<li><strong>Graph Indexing</strong> ：將實體和關係轉化為節點和連接，顯著提高了相關性，特別是在多跳問題的情境下。</ol><p><strong>2. 微調嵌入模型</strong> ( <strong>Fine-tuning Embedding Models)</strong></p><p>確定了Chunk 的適當大小之後，我們需要透過一個嵌入模型（Embedding model）將 Chunk 和查詢嵌入到語意空間中。因此，嵌入模型是否能有效代表整個語料庫變得極為重要。傳統常用的嵌入模型有以下兩種：</p><ul><li><strong>Sentence-Transformers：</strong> 是一種 python 的 BERT NLP 套件，提供各種訓練好的BERT 模型套件，適合單個句的處理。<li><strong>text-embedding-ada-002：</strong> OpenAI 提出的新嵌入模型，適合處理包含256 或 512 Token 的文字區塊。</ul><p>而如今，一些出色的嵌入模型已經問世，例如 AngIE(Li and Li, 2023)、Voyage(VoyageAI, 2023)、BGE(BAAI, 2023) 等，這些模型已經在大型模語料庫上 pre-training。然而，當應用於特定領域時，它們準確捕捉領域特定信息的能力可能會受到限制。</p><p>此外我們還得對嵌入模型進行 Fine tuning，以確保模型能理解用戶查詢，這步對下游應用是必不可少的。嵌入模型 Fine tuning 的方法主要有 2 種：</p><ol><li><strong>領域知識 Fine tuning：</strong> 嵌入模型的 Fine tuning 與 LLM 的 Fine tuning 不一樣，主要差別在嵌入模型的資料集包括查詢（Queries）、語料庫（Corpus）和相關文件（Relevant Docs）。資料集收集的過程非常繁雜，因此 LlamaIndex 專門為此引入了一系列關鍵的類別和函數，旨在簡化工作流程。<li><strong>針對下游任務 Fine tuning：</strong> 目前有研究使用 LLM 來 Fine tuning 嵌入模型。例如，PROMPTAGATOR (Dai <em>et al.</em> , 2022)，如此可以解決一些由於數據不足而難以 Fine tuning 的問題。</ol><h3 id="b--如何協調查詢和文件的語意空間"><span class="me-2">b. ) 如何協調查詢和文件的語意空間?</span><a href="#b--如何協調查詢和文件的語意空間" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>在 RAG 應用中，有些擷取器用同一個嵌入模型來處理查詢和文檔，而有些則使用兩個不同的模型。此外，使用者的原始查詢可能表達不清晰或缺少必要的語義資訊。RAG 使用 2 種關鍵技術，來實現這個目標：</p><ol><li><strong>Query Rewriting</strong></ol><p>方法如 Query2Doc 和 ITER-RETGEN 利用 LLMs，通過將原始查詢與額外的指導信息相結合，創建一個虛擬文檔(Wang <em>et al. ,</em> 2023；Shao <em>et al. ,</em> 2023)。其他還有如 HyDE (Gao <em>et al. ,</em> 2022)、RRR (Ma <em>et al. ,</em> 2023)、STEP-BACKPROMPTING (Zheng <em>et al. ,</em> 2022)等。</p><p>2. <strong>Embedding Transformation</strong></p><p>相較於 Query Rewriting，這是一個更微觀的技術。LlamaIndex 在查詢編碼器後加入一個特殊的適配器，並對其進行微調，從而優化查詢的嵌入表示，使之更適合特定的任務。</p><h3 id="c--根據-llm-的需求調整擷取結果"><span class="me-2">c. ) 根據 LLM 的需求調整擷取結果</span><a href="#c--根據-llm-的需求調整擷取結果" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>上述的方法旨在幫助我們提升擷取的效果，但是那些做法可能不能提升 LLM 模型的準確度，原因在於擷取的結果可能不是很符合 LLM 的偏好，因此如何讓擷取結果往 LLM 的偏好靠齊，是一個重要的領域。</p><ol><li><strong>Fine-tuning Retrievers</strong></ol><p>核心概念是透過從 LLM 獲得的回饋訊號來調整嵌入模型，也就是使用 LLM 提供的分數來指導擷取器的訓練，這相當於用大語言模型來對資料集進行標註。近期的方法如 AAR (Yu <em>et al.</em> , 2023)</p><p>2. <strong>Adapters</strong></p><p>上述的 Fine tuning 方法在實現上會有難度，如 API 的實現與算力的考量。因此，一些研究選擇外接 Adapters 來進行模型對齊。PRCA (Yang <em>et al.</em> , 2023) 在上下文提取階段和獎勵驅動階段訓練適配器，並透過基於 Token 的autoregressiv 策略來優化擷取器的輸出。</p><h3 id="生成generation"><span class="me-2"><strong>生成(Generation)</strong></span><a href="#生成generation" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>生成器是 RAG 的關鍵之一，它負責將擷取到的信息轉換為連貫和流暢的文本。在 RAG 中，生成器的輸入不僅包括典型的上下文信息，還包括通過檢索器獲得的相關文本片段。這種全面的輸入使生成器能夠深入理解問題的上下文，從而產生更具信息性和上下文相關性的回答。生成器會根據擷取到的文字來指導內容的生成，確保產生的內容與擷取資訊一致。</p><p>但擷取的內容五花八門，因此目前有一系列研究在探討生成器的適應性，讓其能應付來自查詢和文件的輸入資料。</p><h3 id="a--如何優化擷取到的訊息"><span class="me-2">a) . 如何優化擷取到的訊息?</span><a href="#a--如何優化擷取到的訊息" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>目前大宗做法是依賴無法調整但訓練完好的 LLM 模型(如 ChatGPT-4)來生成，不過這些 LLM 仍然存在一些問題，例如上下文長度限制和對冗餘資訊的敏感度。為了解決這個問題，目前一些研究開始專注在 <strong>擷取後處理(post-retrieval processing)</strong> ，這個作法是將經由擷取器得到的資訊去做進一步的處理、過濾或最佳化，提高擷取結果的品質，主要有 2 種主流作法：</p><ol><li><strong>資訊壓縮 (Information Compression)</strong></ol><p>即使擷取器能很棒的從龐大的知識庫中擷取到相關信息，但管理大量的擷取信息仍是一個挑戰。目前做法是擴大 LLM 的上下文長度來解決此問題，但這並不能很有效解決問題，上下文長度限制仍是一大問題。因此，壓縮資訊變得必要。資訊壓縮對減少雜訊、解決上下文長度限制和增強生成效果具有重要意義。</p><p>PRCA 透過訓練一個資訊擷取器來解決這個問題(Yang <em>et al.</em> , 2023)。在上下文擷取階段，提供輸入文字 Sinput 時，它能夠產生一個輸出序列 Cextracted，代表從輸入文件中壓縮得到的上下文。 訓練過程旨在最小化 Cextracted 和實際上下文 Ctruth 之間的差異。</p><p>其他如 RECOMP (Xu <em>et al.</em> , 2023) 或 Filter-Ranker (Ma <em>et al.</em> , 2023)。Filter-Ranker 結合了大語言模型 (LLM) 和小語言模型 (SLM) 的優點。SLM 充當過濾器，LLM 則作為排序器。 研究表明，指導 LLM 重排 SLM 識別出的挑戰性樣本，能夠在各種資訊提取 (IE) 任務中帶來顯著的改進。</p><p>2. <strong>重排序 (Reranking)</strong></p><p>主要功能是優化擷取的信息集合。LLM 常常在引入額外上下文時面臨性能下降，而 Reranking 有效地解決了這一問題。其核心概念涉及重新排列文檔記錄，以使最相關的項目優先排在最前，從而限制文檔的總數量。這不僅解決了檢索過程中上下文窗口擴展的挑戰，而且還提升了檢索效率和響應速度。</p><h3 id="b--如何根據擷取到的訊息優化生成器"><span class="me-2">b) . 如何根據擷取到的訊息優化生成器?</span><a href="#b--如何根據擷取到的訊息優化生成器" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>在使用一般 LLM 時，輸入通常只會有一段文字查詢。但在 RAG 中，輸入不僅結合了查詢，還包括了擷取器擷取到的各種文檔，其中包含結構化與非結構化的資訊。這個額外的資訊會顯著影響 LLM 的理解，特別是對於較小的LLM。</p><p>在這種情況下，Fine tuning 模型以適應 「查詢+擷取文檔」的輸入變得至關重要。RAG 中生成器的 Fine tuning 方法與 LLM 的一般微調方法基本一樣。接下來，我們將簡要描述一些涉及數據（格式化/非格式化）和優化功能的代表性工作。</p><ol><li><strong>通用優化流程 (General Optimization Process)</strong></ol><p>Self-mem (Cheng <em>et al.</em> , 2023) 採用了傳統訓練方法。其中給定輸入 x，擷取訊息 z，然後結合(x, z)，模型生成輸出 y。論文探討了兩種主流 Fine tuning方法，分別為 Joint-Encoder (Arora <em>et al.</em> , 2023, Wang <em>et al.</em> , 2022b, Lewis <em>et al.</em> , 2020) 和 Dual-Encoder (Xia <em>et al.</em> , 2019, Cai <em>et al.</em> , 2021, Cheng <em>et al.</em> , 2022)。</p><p>在 Joint-Encoder 中，使用基於 encoder-decoder 的標準模型。其中，encoder 首先對輸入進行編碼，decoder 透過注意力機制結合編碼結果，並以自回歸方式生成 Token。另一方面，在 Dual-Encoder中，系統設置了兩個獨立的 encoder，每個 encoder 分別對輸入 (查詢、上下文) 和文檔進行編碼，之後將輸出依序經由 decoder，進行雙向交叉注意力處理。這兩種架構都利用 Transformer 作為基礎。</p><p>2. <strong>利用對比學習 (Utilizing Contrastive Learning)</strong></p><p>在為 LLM 準備訓練數據的階段中，通常會建立輸入和輸出的配對。這種傳統方法可能導致 「暴露偏差」，即模型僅在個別正確的輸出示例上進行訓練，接觸到單一的正確回饋，無法了解其他可能的生成 Token。這種限制可能會阻礙模型在真實世界中的表現，因為它可能過度適應訓練集中的特定示例，從而降低了其在不同上下文中泛化的能力。</p><p>為了緩解暴露偏差，SURGE (Kang <em>et al.</em> , 2023) 提出使用圖文對比學習。這種方法包括一個對比學習目標，促使模型產生一系列可行且連貫的回應，擴展到訓練數據中遇到的實例之外。這種方法在減少過度適應和加強模型的泛化能力方面至關重要。</p><h3 id="三-rag-生態系-"><span class="me-2">三. RAG 生態系 ?</span><a href="#三-rag-生態系-" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="/assets/fced76fdb8b9/1*fbbUfWHObS2MWzbq6mIo7A.png" class="popup img-link shimmer"><img src="/assets/fced76fdb8b9/1*fbbUfWHObS2MWzbq6mIo7A.png" alt="" loading="lazy"></a></p><p>RAG 的生態系蓬勃發展，在水平領域，從最初的文本問答領域以外，RAG 的應用逐漸拓展到更多模態資料，包括圖像、程式碼、結構化知識、影音等。在這些領域，已經湧現許多相關研究成果。</p><p>而相關的 Technical Stack 發展也滿迅速，如有名的 LangChain 和 LLamaIndex 這樣的關鍵工具，隨著 ChatGPT 的出現迅速獲得了人氣，它們提供了廣泛的與 RAG 相關的 API，並成為LLM 領域的佼佼者。</p><p>同時新興的 Technical Stack 也逐漸在發展，例如，Flowise AI10 優先考慮低代碼方法，使用者能夠透過簡單的拖曳界面部署包括 RAG 在內的 AI 應用。其他技術如 HayStack、Meltano11 和 Cohere Coral12 也因其在該領域的獨特貢獻而受到關注。</p><p>除了專注於 AI 的提供者之外，傳統軟件和雲服務提供者也在擴大其服務範圍，包括以 RAG 為中心的服務。如向量資料庫公司 Weaviate 推出的 Verba7 專注於個人助理應用，而亞馬遜 的 Kendra 提供智能企業搜索服務，允許用戶使用內置連接器在各種內容存儲庫中導航。</p><h3 id="參考資料"><span class="me-2">參考資料</span><a href="#參考資料" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Gao, Yunfan et al. “Retrieval-Augmented Generation for Large Language Models: A Survey.” (2023) .</p><div class="floating-medium-button"> <a href="https://medium.com/@cch.chichieh" target="_blank" class="medium-follow-button"> <svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M13 12C13 15.3137 10.3137 18 7 18C3.68629 18 1 15.3137 1 12C1 8.68629 3.68629 6 7 6C10.3137 6 13 8.68629 13 12Z" fill="currentColor" /><path d="M23 12C23 14.7614 22.5523 17 22 17C21.4477 17 21 14.7614 21 12C21 9.23858 21.4477 7 22 7C22.5523 7 23 9.23858 23 12Z" fill="currentColor" /><path d="M17 12C17 14.7614 16.5523 17 16 17C15.4477 17 15 14.7614 15 12C15 9.23858 15.4477 7 16 7C16.5523 7 17 9.23858 17 12Z" fill="currentColor" /> </svg> Follow me on Medium </a></div><hr /><p><a href="https://www.buymeacoffee.com/chichieh.huang" target="_blank" class="img-link shimmer" ><img src="https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png" alt="Buy Me A Coffee" style="height: 60px !important;width: 217px !important;" loading="lazy"></a></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw me-1"></i> <a href="/categories/rag-%E6%AA%A2%E7%B4%A2%E5%A2%9E%E5%BC%B7%E7%94%9F%E6%88%90/">RAG (檢索增強生成)</a>, <a href="/categories/research/">Research</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw me-1"></i> <a href="/tags/rag/" class="post-tag no-text-decoration" >rag</a> <a href="/tags/llm/" class="post-tag no-text-decoration" >llm</a> <a href="/tags/research/" class="post-tag no-text-decoration" >research</a> <a href="/tags/%E4%B8%AD%E6%96%87/" class="post-tag no-text-decoration" >中文</a> <a href="/tags/fine-tuning/" class="post-tag no-text-decoration" >fine-tuning</a></div><div class=" post-tail-bottom d-flex justify-content-between align-items-center mt-5 pb-2 " ><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper d-flex align-items-center"> <span class="share-label text-muted">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=RAG%20(Retrieval%20Augmented%20Generation):%20%E7%82%BA%E8%87%AA%E7%84%B6%E8%AA%9E%E8%A8%80%E8%99%95%E7%90%86%E6%8F%AD%E9%96%8B%E6%96%B0%E7%AF%87%E7%AB%A0%20-%20ChiChieh%20Huang&url=https%3A%2F%2Fchichieh-huang.com%2Fposts%2Ffced76fdb8b9%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Twitter" aria-label="Twitter"> <i class="fa-fw fa-brands fa-square-x-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=RAG%20(Retrieval%20Augmented%20Generation):%20%E7%82%BA%E8%87%AA%E7%84%B6%E8%AA%9E%E8%A8%80%E8%99%95%E7%90%86%E6%8F%AD%E9%96%8B%E6%96%B0%E7%AF%87%E7%AB%A0%20-%20ChiChieh%20Huang&u=https%3A%2F%2Fchichieh-huang.com%2Fposts%2Ffced76fdb8b9%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Facebook" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fchichieh-huang.com%2Fposts%2Ffced76fdb8b9%2F&text=RAG%20(Retrieval%20Augmented%20Generation):%20%E7%82%BA%E8%87%AA%E7%84%B6%E8%AA%9E%E8%A8%80%E8%99%95%E7%90%86%E6%8F%AD%E9%96%8B%E6%96%B0%E7%AF%87%E7%AB%A0%20-%20ChiChieh%20Huang" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Telegram" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <button id="copy-link" aria-label="Copy link" class="btn small" data-bs-toggle="tooltip" data-bs-placement="top" title="Copy link" data-title-succeed="Link copied successfully!" > <i class="fa-fw fas fa-link pe-none fs-6"></i> </button> </span></div></div></div></article></main><aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 text-muted"><div class="access"><section id="access-lastmod"><h2 class="panel-heading">Recently Updated</h2><ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2"><li class="text-truncate lh-lg"> <a href="/posts/a1d263ce61b4/">Migrating Away From v0 | Switching to Cursor/Windsurf</a><li class="text-truncate lh-lg"> <a href="/posts/5a67f86311d3/">從 v0 搬家 | 改用Cursor/Windsurf 替代</a><li class="text-truncate lh-lg"> <a href="/posts/942b2f15bea4/">我們都在用 AI，但 AI 跟 AI 怎麼溝通？淺談 AI Agent 通訊協定</a><li class="text-truncate lh-lg"> <a href="/posts/a3476af62056/">OpenManus Tutorial: How to Build Your Custom AI Agent in 2025 (Beginner’s Guide)</a><li class="text-truncate lh-lg"> <a href="/posts/d30783070827/">Understanding Reasoning Models & Test-Time Compute: Insights from DeepSeek-R1</a></ul></section><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/%E4%B8%AD%E6%96%87/">中文</a> <a class="post-tag btn btn-outline-primary" href="/tags/llm/">llm</a> <a class="post-tag btn btn-outline-primary" href="/tags/ai/">ai</a> <a class="post-tag btn btn-outline-primary" href="/tags/tutorial/">tutorial</a> <a class="post-tag btn btn-outline-primary" href="/tags/installation/">installation</a> <a class="post-tag btn btn-outline-primary" href="/tags/rag/">rag</a> <a class="post-tag btn btn-outline-primary" href="/tags/research/">research</a> <a class="post-tag btn btn-outline-primary" href="/tags/ai-agent/">ai-agent</a> <a class="post-tag btn btn-outline-primary" href="/tags/artificial-intelligence/">artificial-intelligence</a> <a class="post-tag btn btn-outline-primary" href="/tags/langchain/">langchain</a></div></section></div><div class="toc-border-cover z-3"></div><section id="toc-wrapper" class="invisible position-sticky ps-0 pe-4 pb-4"><h2 class="panel-heading ps-3 pb-2 mb-0">Contents</h2><nav id="toc"></nav></section></aside></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4"><aside id="related-posts" aria-labelledby="related-label"><h3 class="mb-4" id="related-label">Further Reading</h3><nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4"><article class="col"> <a href="/posts/ab70d7117480/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1717580275" data-df="ll" > Jun 5, 2024 </time><h4 class="pt-0 my-2">深入解析 RAG 評估框架：TruLens, RGAR, 與 RAGAs 的比較</h4><div class="text-muted"><p>隨著 RAG 日益發展，有許多 RAG 的變形架構出現，使其成為一個越來越複雜的系統，需要全面性的評估方可監控其效能，提供後續的商業價值。因此，本文旨在探討我們如何全面且廣泛性的評估 RAG 系統，以及 RAG 評估框架的未來方向。</p></div></div></a></article><article class="col"> <a href="/posts/0e4ac8adc6df/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1709807747" data-df="ll" > Mar 7, 2024 </time><h4 class="pt-0 my-2">RAG 優化技巧| 7 大挑戰與解決方式 | 增進你的 LLM</h4><div class="text-muted"><p>儘管 LLM + RAG 的能力已經令人驚嘆，但我們在使用 RAG 優化 LLM 的過程中，還是會遇到了許多挑戰與難題，包括但不限於檢索器返回不準確或不相關的資料，以及LLM基於錯誤或過時資訊生成答案的情況，因此本文旨在提出 RAG 常見的 7 大挑戰，與其各自的優化方案。</p></div></div></a></article><article class="col"> <a href="/posts/d6838febf8c4/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1705777720" data-df="ll" > Jan 21, 2024 </time><h4 class="pt-0 my-2">RAG實作教學，LangChain + Llama2 |創造你的個人LLM</h4><div class="text-muted"><p>在這篇文章中，我們將帶你使用 LangChain + Llama2，一步一步架設自己的 RAG（Retrieval-Augmented Generation）的系統，讓你可以上傳自己的 PDF，並且詢問 LLM 關於 PDF 的訊息。</p></div></div></a></article></nav></aside><nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation"> <a href="/posts/2451807f8ba5/" class="btn btn-outline-primary" aria-label="Older" ><p>用手機就能跑 LLaMA 2! llama.cpp 教學</p></a> <a href="/posts/d6838febf8c4/" class="btn btn-outline-primary" aria-label="Newer" ><p>RAG實作教學，LangChain + Llama2 |創造你的個人LLM</p></a></nav><footer aria-label="Site Info" class=" d-flex flex-column justify-content-center text-muted flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3 " ><p>© <time>2025</time> <a href="https://github.com/wsxqaza12">ChiChieh Huang</a>. <span data-bs-toggle="tooltip" data-bs-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author." >Some rights reserved.</span></p><p>Using the <a data-bs-toggle="tooltip" data-bs-placement="top" title="v7.3.0" href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener" >Chirpy</a> theme for <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>.<br/> Automatically sync posts from Medium with <a href="https://zhgchg.li/posts/en-medium-to-jekyll/" target="_blank">ZhgChg.Li</a>.<br/>Last updated: 2025-06-15 11:02:16 +08:00</p></footer></div></div><div id="search-result-wrapper" class="d-flex justify-content-center d-none"><div class="col-11 content"><div id="search-hints"><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/%E4%B8%AD%E6%96%87/">中文</a> <a class="post-tag btn btn-outline-primary" href="/tags/llm/">llm</a> <a class="post-tag btn btn-outline-primary" href="/tags/ai/">ai</a> <a class="post-tag btn btn-outline-primary" href="/tags/tutorial/">tutorial</a> <a class="post-tag btn btn-outline-primary" href="/tags/installation/">installation</a> <a class="post-tag btn btn-outline-primary" href="/tags/rag/">rag</a> <a class="post-tag btn btn-outline-primary" href="/tags/research/">research</a> <a class="post-tag btn btn-outline-primary" href="/tags/ai-agent/">ai-agent</a> <a class="post-tag btn btn-outline-primary" href="/tags/artificial-intelligence/">artificial-intelligence</a> <a class="post-tag btn btn-outline-primary" href="/tags/langchain/">langchain</a></div></section></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><aside aria-label="Scroll to Top"> <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow"> <i class="fas fa-angle-up"></i> </button></aside></div><div id="mask" class="d-none position-fixed w-100 h-100 z-1"></div><aside id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-bs-animation="true" data-bs-autohide="false" ><div class="toast-header"> <button type="button" class="btn-close ms-auto" data-bs-dismiss="toast" aria-label="Close" ></button></div><div class="toast-body text-center pt-0"><p class="px-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></aside><script> document.addEventListener('DOMContentLoaded', () => { SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<article class="px-1 px-sm-2 px-lg-4 px-xl-0"><header><h2><a href="{url}">{title}</a></h2><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div></header><p>{content}</p></article>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); }); </script>
