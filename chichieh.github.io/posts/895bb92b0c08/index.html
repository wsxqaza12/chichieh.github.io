<!doctype html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="Local GraphRAG llama.cpp: 使用地端 LLM" /><meta name="author" content="ChiChieh Huang" /><meta property="og:locale" content="en" /><meta name="description" content="這篇文章便是希望帶大家一起操作，如何在 Microsoft GraphRAG 中使用llama.cpp 架設的地端 LLM 伺服器，主要會分成兩步驟： A. 啟動 llama.cpp 伺服器 B. Microsoft GraphRAG" /><meta property="og:description" content="這篇文章便是希望帶大家一起操作，如何在 Microsoft GraphRAG 中使用llama.cpp 架設的地端 LLM 伺服器，主要會分成兩步驟： A. 啟動 llama.cpp 伺服器 B. Microsoft GraphRAG" /><link rel="canonical" href="https://chichieh-huang.com/posts/895bb92b0c08/" /><meta property="og:url" content="https://chichieh-huang.com/posts/895bb92b0c08/" /><meta property="og:site_name" content="ChiChieh Huang" /><meta property="og:image" content="https://chichieh-huang.com/assets/895bb92b0c08/1*tInzlVhHANaOweOsiiYiow.png" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2024-11-06T17:27:26+08:00" /><meta name="twitter:card" content="summary_large_image" /><meta property="twitter:image" content="https://chichieh-huang.com/assets/895bb92b0c08/1*tInzlVhHANaOweOsiiYiow.png" /><meta property="twitter:title" content="Local GraphRAG llama.cpp: 使用地端 LLM" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"ChiChieh Huang","url":"https://medium.com/@cch.chichieh"},"dateModified":"2025-02-20T18:55:35+08:00","datePublished":"2024-11-06T17:27:26+08:00","description":"這篇文章便是希望帶大家一起操作，如何在 Microsoft GraphRAG 中使用llama.cpp 架設的地端 LLM 伺服器，主要會分成兩步驟： A. 啟動 llama.cpp 伺服器 B. Microsoft GraphRAG","headline":"Local GraphRAG llama.cpp: 使用地端 LLM","image":"https://chichieh-huang.com/assets/895bb92b0c08/1*tInzlVhHANaOweOsiiYiow.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://chichieh-huang.com/posts/895bb92b0c08/"},"url":"https://chichieh-huang.com/posts/895bb92b0c08/"}</script><title>Local GraphRAG | llama.cpp: 使用地端 LLM | ChiChieh Huang</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="ChiChieh Huang"><meta name="application-name" content="ChiChieh Huang"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.32.2/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/glightbox@3.3.0/dist/css/glightbox.min.css"> <script src="/assets/js/dist/theme.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/glightbox@3.3.0/dist/js/glightbox.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.13/dayjs.min.js,npm/dayjs@1.11.13/locale/en.js,npm/dayjs@1.11.13/plugin/relativeTime.js,npm/dayjs@1.11.13/plugin/localizedFormat.js,npm/tocbot@4.32.2/dist/tocbot.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/app.min.js?baseurl=&register=true" ></script><body><aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end"><header class="profile-wrapper"> <a href="/" id="avatar" class="rounded-circle"><img src="/assets/img/avatar.png" width="112" height="112" alt="avatar" onerror="this.style.display='none'"></a> <a class="site-title d-block" href="/">ChiChieh Huang</a><p class="site-subtitle fst-italic mb-0"><div class="medium-followers-container"> <a href="https://medium.com/@cch.chichieh" target="_blank" class="medium-link"> <span class="followers-count">880+ followers on&nbsp;</span> <svg class="medium-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M13 12C13 15.3137 10.3137 18 7 18C3.68629 18 1 15.3137 1 12C1 8.68629 3.68629 6 7 6C10.3137 6 13 8.68629 13 12Z"/><path d="M23 12C23 14.7614 22.5523 17 22 17C21.4477 17 21 14.7614 21 12C21 9.23858 21.4477 7 22 7C22.5523 7 23 9.23858 23 12Z"/><path d="M17 12C17 14.7614 16.5523 17 16 17C15.4477 17 15 14.7614 15 12C15 9.23858 15.4477 7 16 7C16.5523 7 17 9.23858 17 12Z"/> </svg> <span>Medium</span> </a></div>Hi~ 我專注於 Generative AI 產品開發，熱愛桌球與奇幻小說，並希望透過中文內容與更多人分享 AI 知識，讓技術更貼近社群。</p></header><nav class="flex-column flex-grow-1 w-100 ps-0"><ul class="nav"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle"></i> <span>ABOUT</span> </a></ul></nav><div class="sidebar-bottom d-flex flex-wrap align-items-center w-100"> <button type="button" class="btn btn-link nav-link" aria-label="Switch Mode" id="mode-toggle"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/wsxqaza12" aria-label="github" target="_blank" rel="noopener noreferrer" > <i class="fab fa-github"></i> </a> <a href="" aria-label="linkedin" target="_blank" rel="noopener noreferrer" > <i class="fab fa-linkedin"></i> </a> <a href="javascript:location.href = 'mailto:' + ['cch.chichieh','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></aside><div id="main-wrapper" class="d-flex justify-content-center"><div class="container d-flex flex-column px-xxl-5"><header id="topbar-wrapper" class="flex-shrink-0" aria-label="Top Bar"><div id="topbar" class="d-flex align-items-center justify-content-between px-lg-3 h-100" ><nav id="breadcrumb" aria-label="Breadcrumb"> <span> <a href="/">Home</a> </span> <span>Local GraphRAG | llama.cpp: 使用地端 LLM</span></nav><button type="button" id="sidebar-trigger" class="btn btn-link" aria-label="Sidebar"> <i class="fas fa-bars fa-fw"></i> </button><div id="topbar-title"> Post</div><button type="button" id="search-trigger" class="btn btn-link" aria-label="Search"> <i class="fas fa-search fa-fw"></i> </button> <search id="search" class="align-items-center ms-3 ms-lg-0"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..." > </search> <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button></div></header><div class="row flex-grow-1"><main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4"><article class="px-1" data-toc="true"><header><h1 data-toc-skip>Local GraphRAG | llama.cpp: 使用地端 LLM</h1><p class="post-desc fw-light mb-4">這篇文章便是希望帶大家一起操作，如何在 Microsoft GraphRAG 中使用llama.cpp 架設的地端 LLM 伺服器，主要會分成兩步驟： A. 啟動 llama.cpp 伺服器 B. Microsoft GraphRAG</p><div class="post-meta text-muted"> <span> Posted <time data-ts="1730885246" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > Nov 6, 2024 </time> </span> <span> Updated <time data-ts="1740048935" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > Feb 20, 2025 </time> </span><div class="mt-3 mb-3"> <a href="/assets/895bb92b0c08/1*tInzlVhHANaOweOsiiYiow.png" class="popup img-link preview-img shimmer"><img src="/assets/895bb92b0c08/1*tInzlVhHANaOweOsiiYiow.png" alt="Preview Image" width="1200" height="630" loading="lazy"></a></div><div class="d-flex justify-content-between"> <span> By <em> <a href="https://medium.com/@cch.chichieh">ChiChieh Huang</a> </em> </span><div> <span class="readtime" data-bs-toggle="tooltip" data-bs-placement="bottom" title="1653 words" > <em>9 min</em> read</span></div></div></div></header><div id="toc-bar" class="d-flex align-items-center justify-content-between invisible"> <span class="label text-truncate">Local GraphRAG | llama.cpp: 使用地端 LLM</span> <button type="button" class="toc-trigger btn me-1"> <i class="fa-solid fa-list-ul fa-fw"></i> </button></div><button id="toc-solo-trigger" type="button" class="toc-trigger btn btn-outline-secondary btn-sm"> <span class="label ps-2 pe-1">Contents</span> <i class="fa-solid fa-angle-right fa-fw"></i> </button> <dialog id="toc-popup" class="p-0"><div class="header d-flex flex-row align-items-center justify-content-between"><div class="label text-truncate py-2 ms-4">Local GraphRAG | llama.cpp: 使用地端 LLM</div><button id="toc-popup-close" type="button" class="btn mx-1 my-1 opacity-75"> <i class="fas fa-close"></i> </button></div><div id="toc-popup-content" class="px-4 py-3 pb-4"></div></dialog><div class="content"><h3 id="local-graphrag--llamacpp-使用地端-llm"><span class="me-2">Local GraphRAG | llama.cpp: 使用地端 LLM</span><a href="#local-graphrag--llamacpp-使用地端-llm" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="/assets/895bb92b0c08/1*tInzlVhHANaOweOsiiYiow.png" class="popup img-link shimmer"><img src="/assets/895bb92b0c08/1*tInzlVhHANaOweOsiiYiow.png" alt="" loading="lazy"></a></p><p>在現今的企業應用中，GraphRAG 已成為許多 LLM 應用中的重要功能。然而，Microsoft 的 GraphRAG 需要付費，且必須將資料上傳至商業 LLM 平台，這對於一些企業而言可能並不理想。因此，如何利用自有的 LLM 模型來建立 Microsoft GraphRAG，成為越來越多人關注的解決方案。</p><p>Microsoft GraphRAG 主要是設計給使用者選擇 OpenAI 或 Azure OpenAI 的 LLM 來執行，若你對此技術還不熟悉，可以先參考我先前的 <a href="../ac07991855e6/">教學文章</a> 了解基礎概念。如今，有不少開發者在 GitHub 上提供了開源的 Local GraphRAG 方法，讓大家能夠透過地端的 LLM 來實現相似的效果。以下是兩個值得參考的 repo：</p><ul><li><a href="https://github.com/severian42/GraphRAG-Local-UI" target="_blank"><strong>GraphRAG-Local-UI</strong></a> ：提供了使用者友好的圖形介面（UI），方便操作。<li><a href="https://github.com/TheAiSingularity/graphrag-local-ollama" target="_blank"><strong>graphrag-local-ollama</strong></a> ：較早期的教學資源，指導如何在地端 LLM 上進行 GraphRAG 的應用。</ul><p>上述兩個 repo 都依賴於一個名為 ollama 的工具來創建與 OpenAI API 相容的接口。ollama 的底層架構是基於 llama.cpp，並進行了一些調整，最終提供了一個較為便捷的操作介面。簡單來說，ollama 使用 Go 語言包裹了 llama.cpp，讓使用者可以輕鬆安裝和管理模型。</p><p>然而，由於 ollama 進行了特定調整，其所建立的伺服器無法直接用於 Microsoft GraphRAG，還需要修改 GraphRAG 的部分原始碼才能運行。</p><p>因此，若希望更直接地在地端啟動 OpenAI API 相容伺服器，建議直接使用 llama.cpp，使用 llama.cpp 不僅簡單直觀，也避免了不必要的中間層，大幅提升靈活性和控制性，同時也能更清晰地了解如何使用地端 LLM 來取代 OpenAI 或 Azure OpenAI 的 LLM，並無縫地整合到 Microsoft GraphRAG。</p><p>這篇文章便是希望帶大家一起操作，如何在 Microsoft GraphRAG 中使用llama.cpp 架設的地端 LLM 伺服器，主要會分成兩步驟：</p><p>A. 啟動 llama.cpp 伺服器 B. Microsoft GraphRAG</p><h3 id="a-啟動-llamacpp-伺服器"><span class="me-2">A. 啟動 llama.cpp 伺服器</span><a href="#a-啟動-llamacpp-伺服器" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>這步驟需要啟動 2 個伺服器，一個用於 completion，另一個用於 embedding，架設伺服器的細節可以參考我之前的 <a href="../2451807f8ba5/">文章</a> ，這邊帶大家快速操作。</p><h3 id="a-1-clone-llamacpp-專案"><span class="me-2">A-1. clone llama.cpp 專案</span><a href="#a-1-clone-llamacpp-專案" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>把 <a href="https://github.com/ggerganov/llama.cpp" target="_blank">llama.cpp</a> 的 repo clone 下來</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>git clone https://github.com/ggerganov/llama.cpp.git
</pre></table></code></div></div><h3 id="a-2-使用-makefile-進行編譯"><span class="me-2">A-2. 使用 Makefile 進行編譯</span><a href="#a-2-使用-makefile-進行編譯" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>使用 <code class="language-plaintext highlighter-rouge">make</code> 對 llama.cpp 專案進行編譯，如果你有 GPU 要使用，需看 <a href="https://github.com/ggerganov/llama.cpp/blob/master/docs/build.md#blas-build" target="_blank">llama.cpp文件</a> 找到符合你環境的指令。</p><p>我這邊是使用 CUDA，因此加上 <code class="language-plaintext highlighter-rouge">GGML_CUDA=1</code> 。</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>make <span class="nv">GGML_CUDA</span><span class="o">=</span>1 <span class="c"># 看你的環境為何</span>
</pre></table></code></div></div><h3 id="a-3-準備環境"><span class="me-2">A-3. 準備環境</span><a href="#a-3-準備環境" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>建議使用 conda 來管理</p><div class="language-lua highlighter-rouge"><div class="code-header"> <span data-label-text="Lua"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">conda</span> <span class="n">create</span> <span class="c1">--name llamaCpp python=3.9</span>
<span class="n">conda</span> <span class="n">activate</span> <span class="n">llamaCpp</span>
<span class="n">python3</span> <span class="o">-</span><span class="n">m</span> <span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">r</span> <span class="n">requirements</span><span class="p">.</span><span class="n">txt</span>
</pre></table></code></div></div><h3 id="a-4-轉檔與量化模型"><span class="me-2">A-4. 轉檔與量化模型</span><a href="#a-4-轉檔與量化模型" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>Hugging Face 上可以下載到很多轉檔或量化後的 GGUF 模型，建議大家可以直接下載操作，我將下載後的模型放在 ./models/ 中。</p><p>需要更多細節的朋友可以參考之前的 <a href="../2451807f8ba5/">文章</a> 。</p><h3 id="a-5-啟動-completion-api-server"><span class="me-2">A-5. 啟動 Completion API Server</span><a href="#a-5-啟動-completion-api-server" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>執行以下指令在 8080 port 開啟 Completion API Server，你可以在 http://127.0.0.1:8080 看到啟動的 Server。</p><div class="language-css highlighter-rouge"><div class="code-header"> <span data-label-text="CSS"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre><span class="o">./</span><span class="nt">llama-server</span> <span class="nt">--host</span> <span class="err">0</span><span class="o">.</span><span class="err">0</span><span class="o">.</span><span class="err">0</span><span class="o">.</span><span class="err">0</span> <span class="nt">--port</span> <span class="err">8080</span> <span class="err">\</span>
  <span class="nt">--threads</span> <span class="err">8</span> <span class="err">\</span>
  <span class="nt">--parallel</span> <span class="err">1</span> <span class="err">\</span>
  <span class="nt">--gpu-layers</span> <span class="err">999</span> <span class="err">\</span>
  <span class="nt">--ctx-size</span> <span class="err">0</span> <span class="err">\</span>
  <span class="nt">--n-predict</span> <span class="nt">-1</span> <span class="err">\</span>
  <span class="nt">--defrag-thold</span> <span class="err">1</span> <span class="err">\</span>
  <span class="nt">--model</span> <span class="o">./</span><span class="nt">models</span><span class="o">/</span><span class="nt">qwen2-7b-instruct-fp16</span><span class="nc">.gguf</span>
</pre></table></code></div></div><h3 id="a-6-啟動-embeddings-api-server"><span class="me-2">A-6. 啟動 Embeddings API Server</span><a href="#a-6-啟動-embeddings-api-server" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>接著執行以下指令在 8081 port 開啟 Embeddings API Server，你可以找你喜歡的 Embeddings 模型，不過記得 <a href="https://github.com/ggerganov/llama.cpp" target="_blank">llama.cpp 的 GitHub</a> 看下現在支援的項目， 如最近很紅的 jina-embeddings-v3，llama.cpp 便還沒支援。</p><div class="language-css highlighter-rouge"><div class="code-header"> <span data-label-text="CSS"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
</pre><td class="rouge-code"><pre><span class="o">./</span><span class="nt">llama-server</span> <span class="nt">--host</span> <span class="err">0</span><span class="o">.</span><span class="err">0</span><span class="o">.</span><span class="err">0</span><span class="o">.</span><span class="err">0</span> <span class="nt">--port</span> <span class="err">8081</span> <span class="err">\</span>
  <span class="nt">--threads</span> <span class="err">8</span> <span class="err">\</span>
  <span class="nt">--parallel</span> <span class="err">1</span> <span class="err">\</span>
  <span class="nt">--gpu-layers</span> <span class="err">999</span> <span class="err">\</span>
  <span class="nt">--ctx-size</span> <span class="err">0</span> <span class="err">\</span>
  <span class="nt">--n-predict</span> <span class="nt">-1</span> <span class="err">\</span>
  <span class="nt">--defrag-thold</span> <span class="err">1</span> <span class="err">\</span>
  <span class="nt">--embeddings</span> <span class="err">\</span>
  <span class="nt">--pooling</span> <span class="nt">mean</span> <span class="err">\</span>
  <span class="nt">--batch-size</span> <span class="err">8192</span> <span class="err">\</span>
  <span class="nt">--ubatch-size</span> <span class="err">4096</span> <span class="err">\</span>
  <span class="nt">--model</span> <span class="o">./</span><span class="nt">models</span><span class="o">/</span><span class="nt">qwen2-7b-instruct-fp16</span><span class="nc">.gguf</span>
</pre></table></code></div></div><p>如此便架設好 2 個 API server，啟動時需花點時間，確定完成後便可繼續下面的步驟。</p><h3 id="b-microsoft-graphrag"><span class="me-2">B. Microsoft GraphRAG</span><a href="#b-microsoft-graphrag" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>啟動好伺服器後，我們接著要來使用 Microsoft GraphRAG，對 Microsoft GraphRAG 不熟或想看更多細節可以參考我之前的 <a href="../ac07991855e6/">文章</a> ，這邊一樣帶大家快速操作。</p><h3 id="b-1-環境設置"><span class="me-2">B-1. 環境設置</span><a href="#b-1-環境設置" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>版本要求是 Python 3.10 到 3.12，我使用 conda 建立環境。</p><div class="language-lua highlighter-rouge"><div class="code-header"> <span data-label-text="Lua"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">conda</span> <span class="n">create</span> <span class="o">-</span><span class="n">n</span> <span class="n">GraphRAG</span> <span class="n">python</span><span class="o">=</span><span class="mi">3</span><span class="p">.</span><span class="mi">10</span>
<span class="n">conda</span> <span class="n">activate</span> <span class="n">GraphRAG</span>
<span class="n">pip</span> <span class="n">install</span> <span class="n">graphrag</span>
</pre></table></code></div></div><h3 id="b-2-準備資料夾與文件"><span class="me-2">B-2. 準備資料夾與文件</span><a href="#b-2-準備資料夾與文件" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>我們將官方的參考文件下載下來。</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre><span class="nb">mkdir</span> <span class="nt">-p</span> ./ragtest/input
curl https://www.gutenberg.org/cache/epub/24022/pg24022.txt <span class="o">&gt;</span> ./ragtest/input/book.txt
</pre></table></code></div></div><h3 id="b-3-workspace-初始化設置"><span class="me-2">B-3. Workspace 初始化設置</span><a href="#b-3-workspace-初始化設置" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>python <span class="nt">-m</span> graphrag.index <span class="nt">--init</span> <span class="nt">--root</span> ./ragtest
</pre></table></code></div></div><h3 id="b-4-修改-settingsyaml"><span class="me-2">B-4. 修改 settings.yaml</span><a href="#b-4-修改-settingsyaml" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>接著修改 ./ragtest/settings.yaml，將前面 llama.cpp 啟動的 Completion API Server 與 Embeddings API Server 的 API 路徑輸入在這邊，用以取代 OpenAI API。</p><div class="language-yaml highlighter-rouge"><div class="code-header"> <span data-label-text="YAML"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
18
19
</pre><td class="rouge-code"><pre><span class="na">llm</span><span class="pi">:</span>
  <span class="na">api_key</span><span class="pi">:</span> <span class="s">${GRAPHRAG_API_KEY}</span>
  <span class="na">type</span><span class="pi">:</span> <span class="s">openai_chat</span> <span class="c1"># or azure_openai_chat</span>
  <span class="na">model</span><span class="pi">:</span> <span class="s">qwen2-7b-instruct</span>
  <span class="na">model_supports_json</span><span class="pi">:</span> <span class="kc">true</span> <span class="c1"># recommended if this is available for your model.</span>
  <span class="na">max_tokens</span><span class="pi">:</span> <span class="m">512</span>
  <span class="c1"># request_timeout: 180.0</span>
  <span class="na">api_base</span><span class="pi">:</span> <span class="s">http://localhost:8080</span>
  <span class="na">api_version</span><span class="pi">:</span> <span class="s">v1</span>

<span class="na">embeddings</span><span class="pi">:</span>
  <span class="c1">## parallelization: override the global parallelization settings for embeddings</span>
  <span class="na">async_mode</span><span class="pi">:</span> <span class="s">threaded</span> <span class="c1"># or asyncio</span>
  <span class="na">llm</span><span class="pi">:</span>
    <span class="na">api_key</span><span class="pi">:</span> <span class="s">${GRAPHRAG_API_KEY}</span>
    <span class="na">type</span><span class="pi">:</span> <span class="s">openai_embedding</span> <span class="c1"># or azure_openai_embedding</span>
    <span class="na">model</span><span class="pi">:</span> <span class="s">qwen2-7b-instruct</span>
    <span class="na">api_base</span><span class="pi">:</span> <span class="s">http://localhost:8081</span>
    <span class="na">api_version</span><span class="pi">:</span> <span class="s">v1</span>
</pre></table></code></div></div><h3 id="b-5-執行-indexing-pipeline"><span class="me-2">B-5. 執行 Indexing pipeline</span><a href="#b-5-執行-indexing-pipeline" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>修好完後就可以執行以下指令，開始進行 Indexing pipeline。</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>python <span class="nt">-m</span> graphrag.index <span class="nt">--root</span> ./ragtest
</pre></table></code></div></div><p>大約會跑 1 小時左右，主要看你的 input.txt 大小與電腦速度，這步驟可能會遇到問題，我蒐集了一些我遇到以及常見的問題放在下面，如果你也遇到可以試試看。</p><p>都順利運行完成後，會看到：🚀 ALL workflows completed successfully</p><h3 id="b-6-進行問答"><span class="me-2">B-6. 進行問答</span><a href="#b-6-進行問答" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>使用 Global Search 的方式提出進階問題的範例，其他方式請參考 <a href="https://microsoft.github.io/graphrag/posts/query/overview/" target="_blank">官方文件</a> 。：</p><div class="language-css highlighter-rouge"><div class="code-header"> <span data-label-text="CSS"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
</pre><td class="rouge-code"><pre><span class="nt">python</span> <span class="nt">-m</span> <span class="nt">graphrag</span><span class="nc">.query</span> <span class="err">\</span>
<span class="nt">--root</span> <span class="o">./</span><span class="nt">ragtest</span> <span class="err">\</span>
<span class="nt">--method</span> <span class="nt">global</span> <span class="err">\</span>
<span class="s1">"What are the top themes in this story?"</span>
</pre></table></code></div></div><h3 id="常見問題"><span class="me-2">常見問題：</span><a href="#常見問題" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>1. ❌create_base_entity_graph</p><p>最常見的問題，大多可透過修改 ./ragtest/settings.yaml 中的 llm 的 <code class="language-plaintext highlighter-rouge">max_tokens</code> 與 chunks 的 <code class="language-plaintext highlighter-rouge">size</code> 和 <code class="language-plaintext highlighter-rouge">overlap</code> 解決。</p><p>有時候模型壓縮太多，會影響到模型跟隨指令的能力，也會出現這個問題，這時可以換別的模型再測試。</p><p>細節參考：Github <a href="https://github.com/microsoft/graphrag/issues/437" target="_blank">Issue437</a> 、 <a href="https://github.com/microsoft/graphrag/issues/951" target="_blank">Issue951</a></p><div class="language-yaml highlighter-rouge"><div class="code-header"> <span data-label-text="YAML"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
</pre><td class="rouge-code"><pre><span class="na">llm</span><span class="pi">:</span>
  <span class="na">max_tokens</span><span class="pi">:</span> <span class="m">512</span>

<span class="na">chunks</span><span class="pi">:</span>
  <span class="na">size</span><span class="pi">:</span> <span class="m">600</span>
  <span class="na">overlap</span><span class="pi">:</span> <span class="m">150</span>
</pre></table></code></div></div><p>2. ValueError(“Columns must be same length as key”)</p><p>如果查看 logs 中的有這個問題，一樣也是可以透過修改 chunks 來修正</p><div class="language-yaml highlighter-rouge"><div class="code-header"> <span data-label-text="YAML"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="na">chunks</span><span class="pi">:</span>
  <span class="na">size</span><span class="pi">:</span> <span class="m">600</span>
  <span class="na">overlap</span><span class="pi">:</span> <span class="m">150</span>
</pre></table></code></div></div><p>細節參考：Github <a href="https://github.com/microsoft/graphrag/issues/362" target="_blank">Issue362</a></p><p>3. ❌create_final_community_reports</p><p>這這步驟需要 Context window 比較長的 LLM，因此若你是使用 llama3.1 ，會無法完成這步驟，因為 llama3.1 的 context window 只有 8k。</p><p>細節參考：Github <a href="https://github.com/microsoft/graphrag/issues/374" target="_blank">Issue374</a></p><div class="floating-medium-button"> <a href="https://medium.com/@cch.chichieh" target="_blank" class="medium-follow-button"> <svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M13 12C13 15.3137 10.3137 18 7 18C3.68629 18 1 15.3137 1 12C1 8.68629 3.68629 6 7 6C10.3137 6 13 8.68629 13 12Z" fill="currentColor" /><path d="M23 12C23 14.7614 22.5523 17 22 17C21.4477 17 21 14.7614 21 12C21 9.23858 21.4477 7 22 7C22.5523 7 23 9.23858 23 12Z" fill="currentColor" /><path d="M17 12C17 14.7614 16.5523 17 16 17C15.4477 17 15 14.7614 15 12C15 9.23858 15.4477 7 16 7C16.5523 7 17 9.23858 17 12Z" fill="currentColor" /> </svg> Follow me on Medium </a></div><hr /><p><a href="https://www.buymeacoffee.com/chichieh.huang" target="_blank" class="img-link shimmer" ><img src="https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png" alt="Buy Me A Coffee" style="height: 60px !important;width: 217px !important;" loading="lazy"></a></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw me-1"></i> <a href="/categories/rag-%E6%AA%A2%E7%B4%A2%E5%A2%9E%E5%BC%B7%E7%94%9F%E6%88%90/">RAG (檢索增強生成)</a>, <a href="/categories/tutorial/">Tutorial</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw me-1"></i> <a href="/tags/llm/" class="post-tag no-text-decoration" >llm</a> <a href="/tags/ai/" class="post-tag no-text-decoration" >ai</a> <a href="/tags/tutorial/" class="post-tag no-text-decoration" >tutorial</a> <a href="/tags/graphrag/" class="post-tag no-text-decoration" >graphrag</a> <a href="/tags/%E4%B8%AD%E6%96%87/" class="post-tag no-text-decoration" >中文</a></div><div class=" post-tail-bottom d-flex justify-content-between align-items-center mt-5 pb-2 " ><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper d-flex align-items-center"> <span class="share-label text-muted">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=Local%20GraphRAG%20%7C%20llama.cpp:%20%E4%BD%BF%E7%94%A8%E5%9C%B0%E7%AB%AF%20LLM%20-%20ChiChieh%20Huang&url=https%3A%2F%2Fchichieh-huang.com%2Fposts%2F895bb92b0c08%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Twitter" aria-label="Twitter"> <i class="fa-fw fa-brands fa-square-x-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=Local%20GraphRAG%20%7C%20llama.cpp:%20%E4%BD%BF%E7%94%A8%E5%9C%B0%E7%AB%AF%20LLM%20-%20ChiChieh%20Huang&u=https%3A%2F%2Fchichieh-huang.com%2Fposts%2F895bb92b0c08%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Facebook" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fchichieh-huang.com%2Fposts%2F895bb92b0c08%2F&text=Local%20GraphRAG%20%7C%20llama.cpp:%20%E4%BD%BF%E7%94%A8%E5%9C%B0%E7%AB%AF%20LLM%20-%20ChiChieh%20Huang" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Telegram" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <button id="copy-link" aria-label="Copy link" class="btn small" data-bs-toggle="tooltip" data-bs-placement="top" title="Copy link" data-title-succeed="Link copied successfully!" > <i class="fa-fw fas fa-link pe-none fs-6"></i> </button> </span></div></div></div></article></main><aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 text-muted"><div class="access"><section id="access-lastmod"><h2 class="panel-heading">Recently Updated</h2><ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2"><li class="text-truncate lh-lg"> <a href="/posts/a1d263ce61b4/">Migrating Away From v0 | Switching to Cursor/Windsurf</a><li class="text-truncate lh-lg"> <a href="/posts/5a67f86311d3/">從 v0 搬家 | 改用Cursor/Windsurf 替代</a><li class="text-truncate lh-lg"> <a href="/posts/942b2f15bea4/">我們都在用 AI，但 AI 跟 AI 怎麼溝通？淺談 AI Agent 通訊協定</a><li class="text-truncate lh-lg"> <a href="/posts/a3476af62056/">OpenManus Tutorial: How to Build Your Custom AI Agent in 2025 (Beginner’s Guide)</a><li class="text-truncate lh-lg"> <a href="/posts/d30783070827/">Understanding Reasoning Models & Test-Time Compute: Insights from DeepSeek-R1</a></ul></section><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/%E4%B8%AD%E6%96%87/">中文</a> <a class="post-tag btn btn-outline-primary" href="/tags/llm/">llm</a> <a class="post-tag btn btn-outline-primary" href="/tags/ai/">ai</a> <a class="post-tag btn btn-outline-primary" href="/tags/tutorial/">tutorial</a> <a class="post-tag btn btn-outline-primary" href="/tags/installation/">installation</a> <a class="post-tag btn btn-outline-primary" href="/tags/rag/">rag</a> <a class="post-tag btn btn-outline-primary" href="/tags/research/">research</a> <a class="post-tag btn btn-outline-primary" href="/tags/ai-agent/">ai-agent</a> <a class="post-tag btn btn-outline-primary" href="/tags/artificial-intelligence/">artificial-intelligence</a> <a class="post-tag btn btn-outline-primary" href="/tags/langchain/">langchain</a></div></section></div><div class="toc-border-cover z-3"></div><section id="toc-wrapper" class="invisible position-sticky ps-0 pe-4 pb-4"><h2 class="panel-heading ps-3 pb-2 mb-0">Contents</h2><nav id="toc"></nav></section></aside></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4"><aside id="related-posts" aria-labelledby="related-label"><h3 class="mb-4" id="related-label">Further Reading</h3><nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4"><article class="col"> <a href="/posts/ac07991855e6/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1721387295" data-df="ll" > Jul 19, 2024 </time><h4 class="pt-0 my-2">Knowledge Graph + RAG | Microsoft GraphRAG 實作與視覺化教學</h4><div class="text-muted"><p>探索 Microsoft GraphRAG 結合 Knowledge Graph 與 RAG 的強大技術，提升模型答案品質。了解其實作與視覺化教學，掌握實作步驟與最佳方法，讓您的企業問答系統更精確高效。立即閱讀，快速上手 GraphRAG，掌握資料檢索和問答技術的最新發展。</p></div></div></a></article><article class="col"> <a href="/posts/aeb3d6733a91/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1718627429" data-df="ll" > Jun 17, 2024 </time><h4 class="pt-0 my-2">互動式 AI 虛擬助理教學：LLMAvatarTalk</h4><div class="text-muted"><p>教學如何整合自動語音識別(ASR)、大型語言模型(LLM)、文字到語音(TTS)、LangChain 和音頻驅動的面部動畫(Audio2Face)與虛幻引擎的 Metahuman等技術，創建你的個人互動式 AI 虛擬助理。</p></div></div></a></article><article class="col"> <a href="/posts/ab70d7117480/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1717580275" data-df="ll" > Jun 5, 2024 </time><h4 class="pt-0 my-2">深入解析 RAG 評估框架：TruLens, RGAR, 與 RAGAs 的比較</h4><div class="text-muted"><p>隨著 RAG 日益發展，有許多 RAG 的變形架構出現，使其成為一個越來越複雜的系統，需要全面性的評估方可監控其效能，提供後續的商業價值。因此，本文旨在探討我們如何全面且廣泛性的評估 RAG 系統，以及 RAG 評估框架的未來方向。</p></div></div></a></article></nav></aside><nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation"> <a href="/posts/ac07991855e6/" class="btn btn-outline-primary" aria-label="Older" ><p>Knowledge Graph + RAG | Microsoft GraphRAG 實作與視覺化教學</p></a> <a href="/posts/a8e27ea274ed/" class="btn btn-outline-primary" aria-label="Newer" ><p>AI Avatar | 虛擬人偶的製作與種類</p></a></nav><footer aria-label="Site Info" class=" d-flex flex-column justify-content-center text-muted flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3 " ><p>© <time>2025</time> <a href="https://github.com/wsxqaza12">ChiChieh Huang</a>. <span data-bs-toggle="tooltip" data-bs-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author." >Some rights reserved.</span></p><p>Using the <a data-bs-toggle="tooltip" data-bs-placement="top" title="v7.3.0" href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener" >Chirpy</a> theme for <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>.<br/> Automatically sync posts from Medium with <a href="https://zhgchg.li/posts/en-medium-to-jekyll/" target="_blank">ZhgChg.Li</a>.<br/>Last updated: 2025-06-15 11:02:16 +08:00</p></footer></div></div><div id="search-result-wrapper" class="d-flex justify-content-center d-none"><div class="col-11 content"><div id="search-hints"><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/%E4%B8%AD%E6%96%87/">中文</a> <a class="post-tag btn btn-outline-primary" href="/tags/llm/">llm</a> <a class="post-tag btn btn-outline-primary" href="/tags/ai/">ai</a> <a class="post-tag btn btn-outline-primary" href="/tags/tutorial/">tutorial</a> <a class="post-tag btn btn-outline-primary" href="/tags/installation/">installation</a> <a class="post-tag btn btn-outline-primary" href="/tags/rag/">rag</a> <a class="post-tag btn btn-outline-primary" href="/tags/research/">research</a> <a class="post-tag btn btn-outline-primary" href="/tags/ai-agent/">ai-agent</a> <a class="post-tag btn btn-outline-primary" href="/tags/artificial-intelligence/">artificial-intelligence</a> <a class="post-tag btn btn-outline-primary" href="/tags/langchain/">langchain</a></div></section></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><aside aria-label="Scroll to Top"> <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow"> <i class="fas fa-angle-up"></i> </button></aside></div><div id="mask" class="d-none position-fixed w-100 h-100 z-1"></div><aside id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-bs-animation="true" data-bs-autohide="false" ><div class="toast-header"> <button type="button" class="btn-close ms-auto" data-bs-dismiss="toast" aria-label="Close" ></button></div><div class="toast-body text-center pt-0"><p class="px-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></aside><script> document.addEventListener('DOMContentLoaded', () => { SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<article class="px-1 px-sm-2 px-lg-4 px-xl-0"><header><h2><a href="{url}">{title}</a></h2><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div></header><p>{content}</p></article>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); }); </script>
