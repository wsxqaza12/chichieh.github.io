<!doctype html><html lang="en" ><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7"><meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e"><meta name="mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-status-bar-style" content="black-translucent"><meta name="viewport" content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover" ><meta name="generator" content="Jekyll v4.4.1" /><meta property="og:title" content="LLM 評估教學 EleutherAI LM Evaluation Harness" /><meta name="author" content="ChiChieh Huang" /><meta property="og:locale" content="en" /><meta name="description" content="在上一篇文章中，我們探討了評估大型語言模型評估時應考慮的各項指標和細節。而這篇文章中，我們將深入探討如何具體操作去評估 LLM。這篇我們使用的工具框架是 EleutherAI 的 lm-evaluation-harness，以下會帶你一起實機操作。" /><meta property="og:description" content="在上一篇文章中，我們探討了評估大型語言模型評估時應考慮的各項指標和細節。而這篇文章中，我們將深入探討如何具體操作去評估 LLM。這篇我們使用的工具框架是 EleutherAI 的 lm-evaluation-harness，以下會帶你一起實機操作。" /><link rel="canonical" href="https://chichieh-huang.com/posts/42628a4362f7/" /><meta property="og:url" content="https://chichieh-huang.com/posts/42628a4362f7/" /><meta property="og:site_name" content="ChiChieh Huang" /><meta property="og:image" content="https://chichieh-huang.com/assets/42628a4362f7/1*6AlMGCA3cZK6E3Ef2OrELw.png" /><meta property="og:type" content="article" /><meta property="article:published_time" content="2024-04-13T03:24:49+08:00" /><meta name="twitter:card" content="summary_large_image" /><meta property="twitter:image" content="https://chichieh-huang.com/assets/42628a4362f7/1*6AlMGCA3cZK6E3Ef2OrELw.png" /><meta property="twitter:title" content="LLM 評估教學 EleutherAI LM Evaluation Harness" /> <script type="application/ld+json"> {"@context":"https://schema.org","@type":"BlogPosting","author":{"@type":"Person","name":"ChiChieh Huang","url":"https://medium.com/@cch.chichieh"},"dateModified":"2025-02-20T18:56:41+08:00","datePublished":"2024-04-13T03:24:49+08:00","description":"在上一篇文章中，我們探討了評估大型語言模型評估時應考慮的各項指標和細節。而這篇文章中，我們將深入探討如何具體操作去評估 LLM。這篇我們使用的工具框架是 EleutherAI 的 lm-evaluation-harness，以下會帶你一起實機操作。","headline":"LLM 評估教學 EleutherAI LM Evaluation Harness","image":"https://chichieh-huang.com/assets/42628a4362f7/1*6AlMGCA3cZK6E3Ef2OrELw.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://chichieh-huang.com/posts/42628a4362f7/"},"url":"https://chichieh-huang.com/posts/42628a4362f7/"}</script><title>LLM 評估教學 | EleutherAI LM Evaluation Harness | ChiChieh Huang</title><link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png"><link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png"><link rel="manifest" href="/assets/img/favicons/site.webmanifest"><link rel="shortcut icon" href="/assets/img/favicons/favicon.ico"><meta name="apple-mobile-web-app-title" content="ChiChieh Huang"><meta name="application-name" content="ChiChieh Huang"><meta name="msapplication-TileColor" content="#da532c"><meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml"><meta name="theme-color" content="#ffffff"><link rel="preconnect" href="https://fonts.googleapis.com" ><link rel="dns-prefetch" href="https://fonts.googleapis.com" ><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin><link rel="dns-prefetch" href="https://fonts.gstatic.com" ><link rel="preconnect" href="https://cdn.jsdelivr.net" ><link rel="dns-prefetch" href="https://cdn.jsdelivr.net" ><link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400&family=Source+Sans+Pro:wght@400;600;700;900&display=swap"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.7.1/css/all.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.32.2/dist/tocbot.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/glightbox@3.3.0/dist/css/glightbox.min.css"> <script src="/assets/js/dist/theme.min.js"></script> <script defer src="https://cdn.jsdelivr.net/combine/npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/glightbox@3.3.0/dist/js/glightbox.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.13/dayjs.min.js,npm/dayjs@1.11.13/locale/en.js,npm/dayjs@1.11.13/plugin/relativeTime.js,npm/dayjs@1.11.13/plugin/localizedFormat.js,npm/tocbot@4.32.2/dist/tocbot.min.js"></script> <script defer src="/assets/js/dist/post.min.js"></script> <script defer src="/app.min.js?baseurl=&register=true" ></script><body><aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end"><header class="profile-wrapper"> <a href="/" id="avatar" class="rounded-circle"><img src="/assets/img/avatar.png" width="112" height="112" alt="avatar" onerror="this.style.display='none'"></a> <a class="site-title d-block" href="/">ChiChieh Huang</a><p class="site-subtitle fst-italic mb-0"><div class="medium-followers-container"> <a href="https://medium.com/@cch.chichieh" target="_blank" class="medium-link"> <span class="followers-count">880+ followers on&nbsp;</span> <svg class="medium-icon" viewBox="0 0 24 24" fill="currentColor"><path d="M13 12C13 15.3137 10.3137 18 7 18C3.68629 18 1 15.3137 1 12C1 8.68629 3.68629 6 7 6C10.3137 6 13 8.68629 13 12Z"/><path d="M23 12C23 14.7614 22.5523 17 22 17C21.4477 17 21 14.7614 21 12C21 9.23858 21.4477 7 22 7C22.5523 7 23 9.23858 23 12Z"/><path d="M17 12C17 14.7614 16.5523 17 16 17C15.4477 17 15 14.7614 15 12C15 9.23858 15.4477 7 16 7C16.5523 7 17 9.23858 17 12Z"/> </svg> <span>Medium</span> </a></div>Hi~ 我專注於 Generative AI 產品開發，熱愛桌球與奇幻小說，並希望透過中文內容與更多人分享 AI 知識，讓技術更貼近社群。</p></header><nav class="flex-column flex-grow-1 w-100 ps-0"><ul class="nav"><li class="nav-item"> <a href="/" class="nav-link"> <i class="fa-fw fas fa-home"></i> <span>HOME</span> </a><li class="nav-item"> <a href="/categories/" class="nav-link"> <i class="fa-fw fas fa-stream"></i> <span>CATEGORIES</span> </a><li class="nav-item"> <a href="/tags/" class="nav-link"> <i class="fa-fw fas fa-tags"></i> <span>TAGS</span> </a><li class="nav-item"> <a href="/archives/" class="nav-link"> <i class="fa-fw fas fa-archive"></i> <span>ARCHIVES</span> </a><li class="nav-item"> <a href="/about/" class="nav-link"> <i class="fa-fw fas fa-info-circle"></i> <span>ABOUT</span> </a></ul></nav><div class="sidebar-bottom d-flex flex-wrap align-items-center w-100"> <button type="button" class="btn btn-link nav-link" aria-label="Switch Mode" id="mode-toggle"> <i class="fas fa-adjust"></i> </button> <span class="icon-border"></span> <a href="https://github.com/wsxqaza12" aria-label="github" target="_blank" rel="noopener noreferrer" > <i class="fab fa-github"></i> </a> <a href="" aria-label="linkedin" target="_blank" rel="noopener noreferrer" > <i class="fab fa-linkedin"></i> </a> <a href="javascript:location.href = 'mailto:' + ['cch.chichieh','gmail.com'].join('@')" aria-label="email" > <i class="fas fa-envelope"></i> </a> <a href="/feed.xml" aria-label="rss" > <i class="fas fa-rss"></i> </a></div></aside><div id="main-wrapper" class="d-flex justify-content-center"><div class="container d-flex flex-column px-xxl-5"><header id="topbar-wrapper" class="flex-shrink-0" aria-label="Top Bar"><div id="topbar" class="d-flex align-items-center justify-content-between px-lg-3 h-100" ><nav id="breadcrumb" aria-label="Breadcrumb"> <span> <a href="/">Home</a> </span> <span>LLM 評估教學 | EleutherAI LM Evaluation Harness</span></nav><button type="button" id="sidebar-trigger" class="btn btn-link" aria-label="Sidebar"> <i class="fas fa-bars fa-fw"></i> </button><div id="topbar-title"> Post</div><button type="button" id="search-trigger" class="btn btn-link" aria-label="Search"> <i class="fas fa-search fa-fw"></i> </button> <search id="search" class="align-items-center ms-3 ms-lg-0"> <i class="fas fa-search fa-fw"></i> <input class="form-control" id="search-input" type="search" aria-label="search" autocomplete="off" placeholder="Search..." > </search> <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button></div></header><div class="row flex-grow-1"><main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4"><article class="px-1" data-toc="true"><header><h1 data-toc-skip>LLM 評估教學 | EleutherAI LM Evaluation Harness</h1><p class="post-desc fw-light mb-4">在上一篇文章中，我們探討了評估大型語言模型評估時應考慮的各項指標和細節。而這篇文章中，我們將深入探討如何具體操作去評估 LLM。這篇我們使用的工具框架是 EleutherAI 的 lm-evaluation-harness，以下會帶你一起實機操作。</p><div class="post-meta text-muted"> <span> Posted <time data-ts="1712949889" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > Apr 13, 2024 </time> </span> <span> Updated <time data-ts="1740049001" data-df="ll" data-bs-toggle="tooltip" data-bs-placement="bottom" > Feb 20, 2025 </time> </span><div class="mt-3 mb-3"> <a href="/assets/42628a4362f7/1*6AlMGCA3cZK6E3Ef2OrELw.png" class="popup img-link preview-img shimmer"><img src="/assets/42628a4362f7/1*6AlMGCA3cZK6E3Ef2OrELw.png" alt="Preview Image" width="1200" height="630" loading="lazy"></a></div><div class="d-flex justify-content-between"> <span> By <em> <a href="https://medium.com/@cch.chichieh">ChiChieh Huang</a> </em> </span><div> <span class="readtime" data-bs-toggle="tooltip" data-bs-placement="bottom" title="1979 words" > <em>10 min</em> read</span></div></div></div></header><div id="toc-bar" class="d-flex align-items-center justify-content-between invisible"> <span class="label text-truncate">LLM 評估教學 | EleutherAI LM Evaluation Harness</span> <button type="button" class="toc-trigger btn me-1"> <i class="fa-solid fa-list-ul fa-fw"></i> </button></div><button id="toc-solo-trigger" type="button" class="toc-trigger btn btn-outline-secondary btn-sm"> <span class="label ps-2 pe-1">Contents</span> <i class="fa-solid fa-angle-right fa-fw"></i> </button> <dialog id="toc-popup" class="p-0"><div class="header d-flex flex-row align-items-center justify-content-between"><div class="label text-truncate py-2 ms-4">LLM 評估教學 | EleutherAI LM Evaluation Harness</div><button id="toc-popup-close" type="button" class="btn mx-1 my-1 opacity-75"> <i class="fas fa-close"></i> </button></div><div id="toc-popup-content" class="px-4 py-3 pb-4"></div></dialog><div class="content"><h3 id="llm-評估教學--eleutherai-lm-evaluation-harness"><span class="me-2">LLM 評估教學 | EleutherAI LM Evaluation Harness</span><a href="#llm-評估教學--eleutherai-lm-evaluation-harness" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><a href="/assets/42628a4362f7/1*6AlMGCA3cZK6E3Ef2OrELw.png" class="popup img-link shimmer"><img src="/assets/42628a4362f7/1*6AlMGCA3cZK6E3Ef2OrELw.png" alt="" loading="lazy"></a></p><p>在 <a href="../e81616d30e53/">上一篇文章</a> 中，我們探討了評估 LLM 時應考慮的各項指標和細節。而這篇文章中，我們將深入探討如何具體操作去評估 LLM。這篇我們使用的工具框架是 EleutherAI 的 <code class="language-plaintext highlighter-rouge">lm-evaluation-harness</code> ，這一工具不僅強大而且靈活，且已被多個組織參考進行後續開發，如 Hugging Face 在其 Open LLM Leaderboard 中便廣泛使用。</p><p>相信大家都看過 Hugging Face 的 Open LLM Leaderboard，該榜單提供了一個公開且透明的平台，來展示各個模型的性能表現。這榜單背後主要針對 6 個關鍵 benchmarks 進行評估，因此這篇也主要帶大家使用 <code class="language-plaintext highlighter-rouge">lm-evaluation-harness</code> 去評估這 6 大 benchmarks：</p><ol><li><strong>AI2 Reasoning Challenge (ARC)</strong> — 25-shot： ARC 是一套小學科學問題集，旨在測試人工智能模型在科學推理方面的能力。<li><strong>HellaSwag</strong> — 10-shot： HellaSwag 是一個常識推理測試，對人類來說極其容易（大約95%的人能夠正確回答），但對於當前最先進的模型來說仍是一個挑戰。<li><strong>MMLU</strong> — 10-shot： MMLU測試旨在衡量文本模型在多任務準確性方面的表現。這個測試覆蓋了57項任務，包括小學數學、美國歷史、計算機科學、法律等。<li><strong>TruthfulQA</strong> — 0-shot： TruthfulQA是一個測量模型再現網絡上常見虛假信息傾向的測試。雖然在技術上，TruthfulQA 在 Harness 中是一個 6-shot 任務，因為即使在 0-shot 設定中，每個例子也會預加上 6 Q/A pairs。<li><strong>Winogrande</strong> — 5-shot： Winogrande 是一個大規模、具有對抗性且困難的 Winograd 基準測試，專注於常識推理。<li><strong>GSM8k</strong> — 5-shot： GSM8k 包含了多樣化的小學數學文字問題，旨在衡量模型解決多步驟數學推理問題的能力。</ol><h3 id="步驟1-clone-eleutherai-lm-evaluation-harness"><span class="me-2">步驟1. Clone EleutherAI LM Evaluation Harness</span><a href="#步驟1-clone-eleutherai-lm-evaluation-harness" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>到 <code class="language-plaintext highlighter-rouge">lm-evaluation-harness</code> 的 <a href="https://github.com/EleutherAI/lm-evaluation-harness" target="_blank">GitHub</a> 將評估工具 clone 下來。</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
</pre><td class="rouge-code"><pre>git clone https://github.com/EleutherAI/lm-evaluation-harness
<span class="nb">cd </span>lm-evaluation-harness
</pre></table></code></div></div><h3 id="步驟2-準備環境"><span class="me-2">步驟2. 準備環境</span><a href="#步驟2-準備環境" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>推薦使用 conda 建立一個環境，你可以在 <a href="https://github.com/EleutherAI/lm-evaluation-harness/blob/main/pyproject.toml" target="_blank">pyproject.toml</a> 中找到要求的版本 python ≥ 3.8，與其將會安裝的 packages。</p><div class="language-lua highlighter-rouge"><div class="code-header"> <span data-label-text="Lua"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
</pre><td class="rouge-code"><pre><span class="n">conda</span> <span class="n">create</span> <span class="o">-</span><span class="n">n</span> <span class="n">LLM_evaluate</span> <span class="n">python</span><span class="o">=</span><span class="mi">3</span><span class="p">.</span><span class="mi">8</span>
<span class="n">conda</span> <span class="n">activate</span> <span class="n">LLM_evaluate</span>
<span class="n">pip</span> <span class="n">install</span> <span class="o">-</span><span class="n">e</span> <span class="p">.</span>
</pre></table></code></div></div><h3 id="步驟3-工具介紹"><span class="me-2">步驟3. 工具介紹</span><a href="#步驟3-工具介紹" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><code class="language-plaintext highlighter-rouge">lm-evaluation-harness</code> 支援許多模型種類與商業模型，包含 HuggingFace Hub 上託管的模型，OpenAI、Anthropic 的 API，也有支援 Llama.cpp 或 vLLM 的接口，因此不論你是要評估已開放使用的 LLM 或個人 fine-tuning 後的 LLM，都可以使用這個工具。</p><p>該工具的參數非常多，可以參考其 <a href="https://github.com/EleutherAI/lm-evaluation-harness/blob/main/docs/interface.md" target="_blank">Docs</a> ，以下介紹幾個常用的：</p><ul><li><strong>— model</strong> ：選擇要評估的模型類型，如 <code class="language-plaintext highlighter-rouge">hf</code> , <code class="language-plaintext highlighter-rouge">gguf</code> , <code class="language-plaintext highlighter-rouge">vllm</code> , <code class="language-plaintext highlighter-rouge">openai</code> 等。<li><strong>— model_args</strong> ：模型的位置與參數，可用 huggingface 的倉庫名稱或本地的 <code class="language-plaintext highlighter-rouge">./xxxxx</code> 等。這個參數可以接受1個以上，用 <code class="language-plaintext highlighter-rouge">,</code> 分隔即可。<li><strong>— tasks</strong> ：決定哪些任務要評估，一樣可以接受一個以上。列表可以使用 <code class="language-plaintext highlighter-rouge">lm-eval — tasks list</code> 查看。<li><strong>— device</strong> ：使用的 GPU，要一個以上請使用 <code class="language-plaintext highlighter-rouge">accelerate launcher</code> 或參數 <code class="language-plaintext highlighter-rouge">tensor_parallel_size</code><li><strong>— batch_size</strong> ： <code class="language-plaintext highlighter-rouge">auto</code> 代表自動選擇batch大小<li><strong>— output_path</strong> ：結果儲存位置。<li><strong>— use_cache</strong> ：緩存之前運行的結果，可以避免相同情境重複執行。<li><strong>— log_samples</strong> ： 把評估的過程記錄下來，包括全部的 Prompt 和 ans。</ul><h3 id="步驟4-開始評估"><span class="me-2">步驟4. 開始評估</span><a href="#步驟4-開始評估" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>如上面提到 <code class="language-plaintext highlighter-rouge">lm-evaluation-harness</code> 支援許多模型種類，因此以下會針對幾個常見的例子示範，其他的使用可以以此類推：</p><ol><li>HuggingFace 託管的模型評估<li>本地 HF 模型<li>使用 llama.cpp 的模型</ol><p>評估的 benchmarks 皆選用 HuggingFace 的 6 種指標，你可以使用以下指令查看 <code class="language-plaintext highlighter-rouge">lm-evaluation-harness</code> 支援的所有 task：</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>lm-eval <span class="nt">--tasks</span> list 
</pre></table></code></div></div><h3 id="41-對-huggingface-託管的模型評估"><span class="me-2">4.1 對 HuggingFace 託管的模型評估</span><a href="#41-對-huggingface-託管的模型評估" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>如果你想對 HuggingFace Hub (例如 GPT-J-6B或你自己的模型) 託管的模型進行評估，你可以使用以下指令：</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre>lm_eval <span class="nt">--model</span> hf <span class="se">\</span>
    <span class="nt">--model_args</span> <span class="nv">pretrained</span><span class="o">=</span>EleutherAI/gpt-j-6B <span class="se">\</span>
    <span class="nt">--tasks</span> arc_challenge, hellaswag, mmlu, triviaqa, winogrande, gsm8k <span class="se">\</span>
    <span class="nt">--device</span> cuda:0 <span class="se">\</span>
    <span class="nt">--batch_size</span> auto <span class="se">\</span>
    <span class="nt">--output_path</span> ./eval_out/hf <span class="se">\</span>
    <span class="nt">--use_cache</span> ./eval_cache/hf
</pre></table></code></div></div><h3 id="42-對本地-hf-模型評估"><span class="me-2">4.2 對本地 HF 模型評估</span><a href="#42-對本地-hf-模型評估" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>如果你的 hf model 儲存在電腦中，則可以使用以下：</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
</pre><td class="rouge-code"><pre>lm_eval <span class="nt">--model</span> hf <span class="se">\</span>
    <span class="nt">--model_args</span> <span class="nv">pretrained</span><span class="o">=</span>./model_name <span class="se">\</span>
    <span class="nt">--tasks</span> arc_challenge, hellaswag, mmlu, triviaqa, winogrande, gsm8k <span class="se">\</span>
    <span class="nt">--device</span> cuda:0 <span class="se">\</span>
    <span class="nt">--batch_size</span> auto <span class="se">\</span>
    <span class="nt">--output_path</span> ./eval_out/local_hf <span class="se">\</span>
    <span class="nt">--use_cache</span> ./eval_cache/local_hf
</pre></table></code></div></div><h3 id="43-對使用-llamacpp-的模型評估"><span class="me-2">4.3 對使用 llama.cpp 的模型評估</span><a href="#43-對使用-llamacpp-的模型評估" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p>如果你一直都是使用 llama.cpp 的 <code class="language-plaintext highlighter-rouge">gguf</code> ，那麼我們需要先將 API 開起來，之前 llama.cpp 的 <a href="../2451807f8ba5/">教學</a> 中有提到，可以使用 llama.cpp 內建的 <code class="language-plaintext highlighter-rouge">./server</code> 快速架設 HTPP API，但這目前在 <code class="language-plaintext highlighter-rouge">lm-evaluation-harness</code> 不支援，因此我們需要使用 <a href="https://github.com/abetlen/llama-cpp-python" target="_blank">llama-cpp-python</a> 來架設 API，主要有3步驟：</p><p><strong>I. 切換環境 (可以另開一個tab進行)</strong></p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>conda activate llamaCpp
</pre></table></code></div></div><p><strong>II. 安裝 llama-cpp-python</strong></p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre>pip <span class="nb">install</span> <span class="s1">'llama-cpp-python[server]'</span>
</pre></table></code></div></div><p><strong>III. 啟動 server</strong></p><div class="language-css highlighter-rouge"><div class="code-header"> <span data-label-text="CSS"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
</pre><td class="rouge-code"><pre><span class="nt">python3</span> <span class="nt">-m</span> <span class="nt">llama_cpp</span><span class="nc">.server</span> <span class="nt">--model</span> <span class="nt">models_name</span><span class="nc">.gguf</span>
</pre></table></code></div></div><p>這樣便成功啟用 <a href="https://github.com/abetlen/llama-cpp-python" target="_blank">llama-cpp-python</a> 幫你架設 API，URL 在 http://localhost:8000 與原始 llama.cpp 的 http://localhost:8080 不一樣，可以注意一下。</p><p>之後就可以使用以下指令進行評估：</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
</pre><td class="rouge-code"><pre>lm_eval <span class="se">\</span>
    <span class="nt">--model</span> gguf <span class="se">\</span>
    <span class="nt">--model_args</span> <span class="nv">base_url</span><span class="o">=</span>http://localhost:8000 <span class="se">\</span>
    <span class="nt">--tasks</span> arc_challenge, hellaswag, mmlu, triviaqa, winogrande, gsm8k <span class="se">\</span>
    <span class="nt">--device</span> cuda:0 <span class="se">\</span>
    <span class="nt">--batch_size</span> auto <span class="se">\</span>
    <span class="nt">--output_path</span> ./eval_out/llamacpp <span class="se">\</span>
    <span class="nt">--use_cache</span> ./eval_cache/llamacpp
</pre></table></code></div></div><p><a href="/assets/42628a4362f7/1*64yXk0NCnK3Lo6xjbh5_qg.png" class="popup img-link shimmer"><img src="/assets/42628a4362f7/1*64yXk0NCnK3Lo6xjbh5_qg.png" alt="實機畫面" loading="lazy"></a></p><p>實機畫面</p><h3 id="步驟5-使用-weights--biases-紀錄結果"><span class="me-2">步驟5. 使用 Weights &amp; Biases 紀錄結果</span><a href="#步驟5-使用-weights--biases-紀錄結果" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><code class="language-plaintext highlighter-rouge">lm-evaluation-harness</code> 支援使用 Weights &amp; Biases(W&amp;B)，W&amp;B 是一個機器學習實驗追蹤、視覺化和管理的平台。它被廣泛用於記錄機器學習模型的訓練過程，用於比較不同模型的性能，在這邊則是讓你可以很好的追蹤評估結果。</p><p>要使用 W&amp;B 只需要加入 <code class="language-plaintext highlighter-rouge">wandb_args</code> 參數即可， <code class="language-plaintext highlighter-rouge">project</code> 輸入你在 W&amp;B 中的專案名稱。</p><div class="language-bash highlighter-rouge"><div class="code-header"> <span data-label-text="Shell"><i class="fas fa-code fa-fw small"></i></span> <button aria-label="copy" data-title-succeed="Copied!"><i class="far fa-clipboard"></i></button></div><div class="highlight"><code><table class="rouge-table"><tbody><tr><td class="rouge-gutter gl"><pre class="lineno">1
2
3
4
5
6
7
8
9
10
</pre><td class="rouge-code"><pre>lm_eval <span class="se">\</span>
    <span class="nt">--model</span> gguf <span class="se">\</span>
    <span class="nt">--model_args</span> <span class="nv">base_url</span><span class="o">=</span>http://localhost:8000 <span class="se">\</span>
    <span class="nt">--tasks</span> arc_challenge, hellaswag, mmlu, triviaqa, winogrande, gsm8k <span class="se">\</span>
    <span class="nt">--device</span> cuda:0 <span class="se">\</span>
    <span class="nt">--batch_size</span> auto <span class="se">\</span>
    <span class="nt">--output_path</span> ./eval_out/llamacpp <span class="se">\</span>
    <span class="nt">--use_cache</span> ./eval_cache/llamacpp <span class="se">\</span>
    <span class="nt">--wandb_args</span> <span class="nv">project</span><span class="o">=</span>llm_eval_benchmark <span class="se">\</span>
    <span class="nt">--log_samples</span>
</pre></table></code></div></div><p>接下來 W&amp;B 會提供我們三個選項：</p><p><a href="/assets/42628a4362f7/1*xzHPMojlvb1u6caMm7SW2g.png" class="popup img-link shimmer"><img src="/assets/42628a4362f7/1*xzHPMojlvb1u6caMm7SW2g.png" alt="" loading="lazy"></a></p><p>1. Create a W&amp;B account: 如果你沒有 W&amp;B 帳戶，選擇這個選項會引導你到 <a href="https://wandb.ai/authorize?signup=true" target="_blank">W&amp;B官網</a> 註冊，接遮辦好後就可以拿到 API KEY，再回來輸入即可。</p><p><a href="/assets/42628a4362f7/1*C0JQZHidBjnKJi08o_iLbg.png" class="popup img-link shimmer"><img src="/assets/42628a4362f7/1*C0JQZHidBjnKJi08o_iLbg.png" alt="" loading="lazy"></a></p><p>2. Use an existing W&amp;B account: 如果你已經有 W&amp;B 帳戶，那麼跟著指示走就可以拿到你的 API KEY，假設你在 (1) Create a W&amp;B account 找不到 API KEY 的話，可以用這邊的引導拿到。</p><p><a href="/assets/42628a4362f7/1*3AQEMuyxZMo6EWO58oJTew.png" class="popup img-link shimmer"><img src="/assets/42628a4362f7/1*3AQEMuyxZMo6EWO58oJTew.png" alt="" loading="lazy"></a></p><p>3. Don’t visualize my results: 如果你不想註冊登入，你還是可以正常使用 W&amp;B 紀錄結果，結果會儲存在 local，只是不能用網站的視覺化功能察看。</p><p>備註：你的 API KEY 會保存在 ~/.netrc 中，下次使用就不需要再選 3 個選項，但如果你想換帳戶的話，可以把文件刪掉重來。</p><p>輸入完 API KEY 後系統就會自動開始評估，等評估完後，你的結果會直接同步到 W&amp;B。</p><p><a href="/assets/42628a4362f7/1*2Y6WCkLHyuTF4x8-pPdfdw.png" class="popup img-link shimmer"><img src="/assets/42628a4362f7/1*2Y6WCkLHyuTF4x8-pPdfdw.png" alt="" loading="lazy"></a></p><p>接著你可以用上面的連結進到你的 W&amp;B Project 中，結果已經視覺化呈現在網站上。</p><p><a href="/assets/42628a4362f7/1*MunVF8D81F3Gx-PkJwwKjQ.png" class="popup img-link shimmer"><img src="/assets/42628a4362f7/1*MunVF8D81F3Gx-PkJwwKjQ.png" alt="" loading="lazy"></a></p><h3 id="結論"><span class="me-2">結論</span><a href="#結論" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3><p><code class="language-plaintext highlighter-rouge">lm-evaluation-harness</code> 是一個很好用的工具，提供了一個強大且靈活的平台，可以評估各種不同的模型，非常適合一般使用者進行實驗和研究，希望透過這篇教學能讓你快速評估你的模型。</p><p>另外，除了 <code class="language-plaintext highlighter-rouge">lm-evaluation-harness</code> 外，市面上還有許多其他專門為 LLM 評估設計的框架，例如 LangChain 的 LangSmith、confidence-ai 的 DeepEval、TruEra 等。這些工具和框架各有千秋，你可以根據自己的具體需求和模型特性選擇最適合的評估工具。</p><div class="floating-medium-button"> <a href="https://medium.com/@cch.chichieh" target="_blank" class="medium-follow-button"> <svg width="24" height="24" viewBox="0 0 24 24" fill="none"><path d="M13 12C13 15.3137 10.3137 18 7 18C3.68629 18 1 15.3137 1 12C1 8.68629 3.68629 6 7 6C10.3137 6 13 8.68629 13 12Z" fill="currentColor" /><path d="M23 12C23 14.7614 22.5523 17 22 17C21.4477 17 21 14.7614 21 12C21 9.23858 21.4477 7 22 7C22.5523 7 23 9.23858 23 12Z" fill="currentColor" /><path d="M17 12C17 14.7614 16.5523 17 16 17C15.4477 17 15 14.7614 15 12C15 9.23858 15.4477 7 16 7C16.5523 7 17 9.23858 17 12Z" fill="currentColor" /> </svg> Follow me on Medium </a></div><hr /><p><a href="https://www.buymeacoffee.com/chichieh.huang" target="_blank" class="img-link shimmer" ><img src="https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png" alt="Buy Me A Coffee" style="height: 60px !important;width: 217px !important;" loading="lazy"></a></p></div><div class="post-tail-wrapper text-muted"><div class="post-meta mb-3"> <i class="far fa-folder-open fa-fw me-1"></i> <a href="/categories/llm-%E5%A4%A7%E5%9E%8B%E8%AA%9E%E8%A8%80%E6%A8%A1%E5%9E%8B/">LLM (大型語言模型)</a>, <a href="/categories/tutorial/">Tutorial</a></div><div class="post-tags"> <i class="fa fa-tags fa-fw me-1"></i> <a href="/tags/llm/" class="post-tag no-text-decoration" >llm</a> <a href="/tags/evaluation/" class="post-tag no-text-decoration" >evaluation</a> <a href="/tags/artificial-intelligence/" class="post-tag no-text-decoration" >artificial-intelligence</a> <a href="/tags/programming/" class="post-tag no-text-decoration" >programming</a> <a href="/tags/%E4%B8%AD%E6%96%87/" class="post-tag no-text-decoration" >中文</a></div><div class=" post-tail-bottom d-flex justify-content-between align-items-center mt-5 pb-2 " ><div class="license-wrapper"> This post is licensed under <a href="https://creativecommons.org/licenses/by/4.0/"> CC BY 4.0 </a> by the author.</div><div class="share-wrapper d-flex align-items-center"> <span class="share-label text-muted">Share</span> <span class="share-icons"> <a href="https://twitter.com/intent/tweet?text=LLM%20%E8%A9%95%E4%BC%B0%E6%95%99%E5%AD%B8%20%7C%20EleutherAI%20LM%20Evaluation%20Harness%20-%20ChiChieh%20Huang&url=https%3A%2F%2Fchichieh-huang.com%2Fposts%2F42628a4362f7%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Twitter" aria-label="Twitter"> <i class="fa-fw fa-brands fa-square-x-twitter"></i> </a> <a href="https://www.facebook.com/sharer/sharer.php?title=LLM%20%E8%A9%95%E4%BC%B0%E6%95%99%E5%AD%B8%20%7C%20EleutherAI%20LM%20Evaluation%20Harness%20-%20ChiChieh%20Huang&u=https%3A%2F%2Fchichieh-huang.com%2Fposts%2F42628a4362f7%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Facebook" aria-label="Facebook"> <i class="fa-fw fab fa-facebook-square"></i> </a> <a href="https://t.me/share/url?url=https%3A%2F%2Fchichieh-huang.com%2Fposts%2F42628a4362f7%2F&text=LLM%20%E8%A9%95%E4%BC%B0%E6%95%99%E5%AD%B8%20%7C%20EleutherAI%20LM%20Evaluation%20Harness%20-%20ChiChieh%20Huang" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Telegram" aria-label="Telegram"> <i class="fa-fw fab fa-telegram"></i> </a> <button id="copy-link" aria-label="Copy link" class="btn small" data-bs-toggle="tooltip" data-bs-placement="top" title="Copy link" data-title-succeed="Link copied successfully!" > <i class="fa-fw fas fa-link pe-none fs-6"></i> </button> </span></div></div></div></article></main><aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 text-muted"><div class="access"><section id="access-lastmod"><h2 class="panel-heading">Recently Updated</h2><ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2"><li class="text-truncate lh-lg"> <a href="/posts/a1d263ce61b4/">Migrating Away From v0 | Switching to Cursor/Windsurf</a><li class="text-truncate lh-lg"> <a href="/posts/5a67f86311d3/">從 v0 搬家 | 改用Cursor/Windsurf 替代</a><li class="text-truncate lh-lg"> <a href="/posts/942b2f15bea4/">我們都在用 AI，但 AI 跟 AI 怎麼溝通？淺談 AI Agent 通訊協定</a><li class="text-truncate lh-lg"> <a href="/posts/a3476af62056/">OpenManus Tutorial: How to Build Your Custom AI Agent in 2025 (Beginner’s Guide)</a><li class="text-truncate lh-lg"> <a href="/posts/d30783070827/">Understanding Reasoning Models & Test-Time Compute: Insights from DeepSeek-R1</a></ul></section><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/%E4%B8%AD%E6%96%87/">中文</a> <a class="post-tag btn btn-outline-primary" href="/tags/llm/">llm</a> <a class="post-tag btn btn-outline-primary" href="/tags/ai/">ai</a> <a class="post-tag btn btn-outline-primary" href="/tags/tutorial/">tutorial</a> <a class="post-tag btn btn-outline-primary" href="/tags/installation/">installation</a> <a class="post-tag btn btn-outline-primary" href="/tags/rag/">rag</a> <a class="post-tag btn btn-outline-primary" href="/tags/research/">research</a> <a class="post-tag btn btn-outline-primary" href="/tags/ai-agent/">ai-agent</a> <a class="post-tag btn btn-outline-primary" href="/tags/artificial-intelligence/">artificial-intelligence</a> <a class="post-tag btn btn-outline-primary" href="/tags/langchain/">langchain</a></div></section></div><div class="toc-border-cover z-3"></div><section id="toc-wrapper" class="invisible position-sticky ps-0 pe-4 pb-4"><h2 class="panel-heading ps-3 pb-2 mb-0">Contents</h2><nav id="toc"></nav></section></aside></div><div class="row"><div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4"><aside id="related-posts" aria-labelledby="related-label"><h3 class="mb-4" id="related-label">Further Reading</h3><nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4"><article class="col"> <a href="/posts/e81616d30e53/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1711745115" data-df="ll" > Mar 30, 2024 </time><h4 class="pt-0 my-2">LLM 評估方法指南：趨勢、指標與未來方向</h4><div class="text-muted"><p>在過去的幾年裡，LLM 在自然語言處理 NLP 領域取得了驚人的進步，成為許多應用的核心技術，包括自動回答系統、文本生成、翻譯等等。隨著這些模型能力日益增強，確保模型既準確又公正就顯得非常重要，而這就引伸出一個根本性的問題：我們怎麼評估模型好不好?</p></div></div></a></article><article class="col"> <a href="/posts/2451807f8ba5/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1705338474" data-df="ll" > Jan 16, 2024 </time><h4 class="pt-0 my-2">用手機就能跑 LLaMA 2! llama.cpp 教學</h4><div class="text-muted"><p>使用 llama.cpp 建立屬於你的 LLM</p></div></div></a></article><article class="col"> <a href="/posts/d4374ed248d9/" class="post-preview card h-100"><div class="card-body"> <time data-ts="1705252407" data-df="ll" > Jan 15, 2024 </time><h4 class="pt-0 my-2">建立屬於你的 LLM | Llama2 教學</h4><div class="text-muted"><p>一步一步下載使用 Llama2 教學</p></div></div></a></article></nav></aside><nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation"> <a href="/posts/e81616d30e53/" class="btn btn-outline-primary" aria-label="Older" ><p>LLM 評估方法指南：趨勢、指標與未來方向</p></a> <a href="/posts/ab70d7117480/" class="btn btn-outline-primary" aria-label="Newer" ><p>深入解析 RAG 評估框架：TruLens, RGAR, 與 RAGAs 的比較</p></a></nav><footer aria-label="Site Info" class=" d-flex flex-column justify-content-center text-muted flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3 " ><p>© <time>2025</time> <a href="https://github.com/wsxqaza12">ChiChieh Huang</a>. <span data-bs-toggle="tooltip" data-bs-placement="top" title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author." >Some rights reserved.</span></p><p>Using the <a data-bs-toggle="tooltip" data-bs-placement="top" title="v7.3.0" href="https://github.com/cotes2020/jekyll-theme-chirpy" target="_blank" rel="noopener" >Chirpy</a> theme for <a href="https://jekyllrb.com" target="_blank" rel="noopener">Jekyll</a>.<br/> Automatically sync posts from Medium with <a href="https://zhgchg.li/posts/en-medium-to-jekyll/" target="_blank">ZhgChg.Li</a>.<br/>Last updated: 2025-06-15 11:02:16 +08:00</p></footer></div></div><div id="search-result-wrapper" class="d-flex justify-content-center d-none"><div class="col-11 content"><div id="search-hints"><section><h2 class="panel-heading">Trending Tags</h2><div class="d-flex flex-wrap mt-3 mb-1 me-3"> <a class="post-tag btn btn-outline-primary" href="/tags/%E4%B8%AD%E6%96%87/">中文</a> <a class="post-tag btn btn-outline-primary" href="/tags/llm/">llm</a> <a class="post-tag btn btn-outline-primary" href="/tags/ai/">ai</a> <a class="post-tag btn btn-outline-primary" href="/tags/tutorial/">tutorial</a> <a class="post-tag btn btn-outline-primary" href="/tags/installation/">installation</a> <a class="post-tag btn btn-outline-primary" href="/tags/rag/">rag</a> <a class="post-tag btn btn-outline-primary" href="/tags/research/">research</a> <a class="post-tag btn btn-outline-primary" href="/tags/ai-agent/">ai-agent</a> <a class="post-tag btn btn-outline-primary" href="/tags/artificial-intelligence/">artificial-intelligence</a> <a class="post-tag btn btn-outline-primary" href="/tags/langchain/">langchain</a></div></section></div><div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div></div></div></div><aside aria-label="Scroll to Top"> <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow"> <i class="fas fa-angle-up"></i> </button></aside></div><div id="mask" class="d-none position-fixed w-100 h-100 z-1"></div><aside id="notification" class="toast" role="alert" aria-live="assertive" aria-atomic="true" data-bs-animation="true" data-bs-autohide="false" ><div class="toast-header"> <button type="button" class="btn-close ms-auto" data-bs-dismiss="toast" aria-label="Close" ></button></div><div class="toast-body text-center pt-0"><p class="px-2 mb-3">A new version of content is available.</p><button type="button" class="btn btn-primary" aria-label="Update"> Update </button></div></aside><script> document.addEventListener('DOMContentLoaded', () => { SimpleJekyllSearch({ searchInput: document.getElementById('search-input'), resultsContainer: document.getElementById('search-results'), json: '/assets/js/data/search.json', searchResultTemplate: '<article class="px-1 px-sm-2 px-lg-4 px-xl-0"><header><h2><a href="{url}">{title}</a></h2><div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1"> {categories} {tags}</div></header><p>{content}</p></article>', noResultsText: '<p class="mt-5">Oops! No results found.</p>', templateMiddleware: function(prop, value, template) { if (prop === 'categories') { if (value === '') { return `${value}`; } else { return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`; } } if (prop === 'tags') { if (value === '') { return `${value}`; } else { return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`; } } } }); }); </script>
